[{"categories":["coding"],"contents":"Preface Perl is a powerful tool to handle text processing. However, the learning curve might be steep due to some unusual syntax. I find myself even need to revisit the doc sometimes if I don\u0026rsquo;t use it often, so this post I\u0026rsquo;ll write down some commonly used patterns when it comes to text processing. That said this post is updated from time to time so remember to come back!\nWhen used as a command line tool, perl is powerful enough to replace traditional text processing tools like sed, awk, grep, tr etc.. Actually using perl instead of grep and tr might be a little overkill in most cases but the functionalities of sed and awk can be almost replced. I recommend someone who starts learning text processing and regex to start with Perl. The reasons are:\nPerl is installed by default almost on every Linux distribution. The regex syntax used by Perl follows PCRE which is more intuitive for someone comes from Python and JavaScript world. Perl is a fully fledged language compared sed and awk. Extra modules is needed. Without furthur ado, let\u0026rsquo;s get started!\nPS: The sample text used in this post is from loghub.\nPPS: Some content is copied from Perl documents.\nCommand line Line matching (grep) cat \u0026lt;\u0026lt;EOF | perl -lne \u0026#39;print if /sshd/\u0026#39; Jun 15 04:06:18 combo su(pam_unix)[21416]: session opened for user cyrus by (uid=0) Jun 15 04:06:20 combo logrotate: ALERT exited abnormally with [1] Jun 15 04:12:42 combo su(pam_unix)[22644]: session opened for user news by (uid=0) Jun 15 12:12:34 combo sshd(pam_unix)[23397]: authentication failure; logname= uid=0 euid=0 tty=NODEVssh ruser= rhost=218.188.2.4 EOF Jun 15 12:12:34 combo sshd(pam_unix)[23397]: authentication failure; logname= uid=0 euid=0 tty=NODEVssh ruser= rhost=218.188.2.4 Print matched only (grep) cat \u0026lt;\u0026lt;EOF | perl -lne \u0026#39;/(pam_unix)/ and print $1\u0026#39; Jun 15 04:06:18 combo su(pam_unix)[21416]: session opened for user cyrus by (uid=0) Jun 15 04:06:20 combo logrotate: ALERT exited abnormally with [1] Jun 15 04:12:42 combo su(pam_unix)[22644]: session opened for user news by (uid=0) Jun 15 12:12:34 combo sshd(pam_unix)[23397]: authentication failure; logname= uid=0 euid=0 tty=NODEVssh ruser= rhost=218.188.2.4 EOF pam_unix pam_unix pam_unix Substitution (sed) cat \u0026lt;\u0026lt;EOF | perl -lpe \u0026#39;s/^Jun/Aug/\u0026#39; Jun 15 04:06:18 combo su(pam_unix)[21416]: session opened for user cyrus by (uid=0) Jun 15 04:06:20 combo logrotate: ALERT exited abnormally with [1] Jun 15 04:12:42 combo su(pam_unix)[22644]: session opened for user news by (uid=0) Jun 15 12:12:34 combo sshd(pam_unix)[23397]: authentication failure; logname= uid=0 euid=0 tty=NODEVssh ruser= rhost=218.188.2.4 EOF Aug 15 04:06:18 combo su(pam_unix)[21416]: session opened for user cyrus by (uid=0) Aug 15 04:06:20 combo logrotate: ALERT exited abnormally with [1] Aug 15 04:12:42 combo su(pam_unix)[22644]: session opened for user news by (uid=0) Aug 15 12:12:34 combo sshd(pam_unix)[23397]: authentication failure; logname= uid=0 euid=0 tty=NODEVssh ruser= rhost=218.188.2.4 Substitute on matches (awk) cat \u0026lt;\u0026lt;EOF | perl -lne \u0026#39;/uid=0/ and s/cyrus/foobar/ and print\u0026#39; Jun 15 04:06:18 combo su(pam_unix)[21416]: session opened for user cyrus by (uid=0) Jun 15 04:06:20 combo logrotate: ALERT exited abnormally with [1] Jun 15 04:12:42 combo su(pam_unix)[22644]: session opened for user news by (uid=0) Jun 15 12:12:34 combo sshd(pam_unix)[23397]: authentication failure; logname= uid=0 euid=0 tty=NODEVssh ruser= rhost=218.188.2.4 EOF Jun 15 04:06:18 combo su(pam_unix)[21416]: session opened for user foobar by (uid=0) Splitting (cut) By default Perl splits by spaces.\ncat \u0026lt;\u0026lt;EOF | perl -lane \u0026#39;print $F[4]\u0026#39; Jun 15 04:06:18 combo su(pam_unix)[21416]: session opened for user cyrus by (uid=0) Jun 15 04:06:20 combo logrotate: ALERT exited abnormally with [1] Jun 15 04:12:42 combo su(pam_unix)[22644]: session opened for user news by (uid=0) Jun 15 12:12:34 combo sshd(pam_unix)[23397]: authentication failure; logname= uid=0 euid=0 tty=NODEVssh ruser= rhost=218.188.2.4 EOF su(pam_unix)[21416]: logrotate: su(pam_unix)[22644]: sshd(pam_unix)[23397]: Specify patterns.\ncat \u0026lt;\u0026lt;EOF | perl -F\u0026#39;:\u0026#39; -lane \u0026#39;print $F[3]\u0026#39; Jun 15 04:06:18 combo su(pam_unix)[21416]: session opened for user cyrus by (uid=0) Jun 15 04:06:20 combo logrotate: ALERT exited abnormally with [1] Jun 15 04:12:42 combo su(pam_unix)[22644]: session opened for user news by (uid=0) Jun 15 12:12:34 combo sshd(pam_unix)[23397]: authentication failure; logname= uid=0 euid=0 tty=NODEVssh ruser= rhost=218.188.2.4 EOF session opened for user cyrus by (uid=0) ALERT exited abnormally with [1] session opened for user news by (uid=0) authentication failure; logname= uid=0 euid=0 tty=NODEVssh ruser= rhost=218.188.2.4 Transformation (tr) cat \u0026lt;\u0026lt;EOF | perl -lpe \u0026#39;tr/a-z/A-Z/\u0026#39; Jun 15 04:06:18 combo su(pam_unix)[21416]: session opened for user cyrus by (uid=0) Jun 15 04:06:20 combo logrotate: ALERT exited abnormally with [1] Jun 15 04:12:42 combo su(pam_unix)[22644]: session opened for user news by (uid=0) Jun 15 12:12:34 combo sshd(pam_unix)[23397]: authentication failure; logname= uid=0 euid=0 tty=NODEVssh ruser= rhost=218.188.2.4 EOF JUN 15 04:06:18 COMBO SU(PAM_UNIX)[21416]: SESSION OPENED FOR USER CYRUS BY (UID=0) JUN 15 04:06:20 COMBO LOGROTATE: ALERT EXITED ABNORMALLY WITH [1] JUN 15 04:12:42 COMBO SU(PAM_UNIX)[22644]: SESSION OPENED FOR USER NEWS BY (UID=0) JUN 15 12:12:34 COMBO SSHD(PAM_UNIX)[23397]: AUTHENTICATION FAILURE; LOGNAME= UID=0 EUID=0 TTY=NODEVSSH RUSER= RHOST=218.188.2.4 Remove duplicated lines (uniq) cat \u0026lt;\u0026lt;EOF | perl -lne \u0026#39;print unless $a{$_}++\u0026#39; Jun 15 04:06:18 combo su(pam_unix)[21416]: session opened for user cyrus by (uid=0) Jun 15 04:06:20 combo logrotate: ALERT exited abnormally with [1] Jun 15 04:12:42 combo su(pam_unix)[22644]: session opened for user news by (uid=0) Jun 15 12:12:34 combo sshd(pam_unix)[23397]: authentication failure; logname= uid=0 euid=0 tty=NODEVssh ruser= rhost=218.188.2.4 Jun 15 04:06:18 combo su(pam_unix)[21416]: session opened for user cyrus by (uid=0) Jun 15 04:06:20 combo logrotate: ALERT exited abnormally with [1] Jun 15 04:12:42 combo su(pam_unix)[22644]: session opened for user news by (uid=0) Jun 15 12:12:34 combo sshd(pam_unix)[23397]: authentication failure; logname= uid=0 euid=0 tty=NODEVssh ruser= rhost=218.188.2.4 EOF Jun 15 04:06:18 combo su(pam_unix)[21416]: session opened for user cyrus by (uid=0) Jun 15 04:06:20 combo logrotate: ALERT exited abnormally with [1] Jun 15 04:12:42 combo su(pam_unix)[22644]: session opened for user news by (uid=0) Jun 15 12:12:34 combo sshd(pam_unix)[23397]: authentication failure; logname= uid=0 euid=0 tty=NODEVssh ruser= rhost=218.188.2.4 Language quirks For quick references:\nPerl intro: https://perldoc.perl.org/perlintro Perl syntax: https://perldoc.perl.org/perlsyn Perl regex: https://perldoc.perl.org/perlre Perl operators: https://perldoc.perl.org/perlop Perl subroutine: https://perldoc.perl.org/perlsub $_ and @_ The $_ and @_ are commonly used to represent the implicit variable/array in the current context. Expressions like string matching can refer to $_ by default without specifying it. Also functions like print can also refer to $_ by just calling it.\nRead from stdin Use \u0026lt;\u0026gt; or \u0026lt;STDIN\u0026gt; to read from stdin line by line. Using this should be careful since it could eat a lot memory.\nmy @lines = \u0026lt;\u0026gt;; A better way to handle it:\nwhile (\u0026lt;\u0026gt;) { print($_); } Scalar Denoted by $ sigil.\nmy $foo = \u0026#34;foo\u0026#34;; Array Denoted by @ sigil.\nmy @array = (123, \u0026#34;foo\u0026#34;, undef, \u0026#34;bar\u0026#34;); When accessing by the index, one can use either $ or @. In most cases, they are equivalent. However, they do have slight different meanings. $ implies the result is a scalar while @ indicates the result could be an array. The example can be seen below.\nmy @array = (\u0026#34;foo\u0026#34;, \u0026#34;bar\u0026#34;, \u0026#34;baz\u0026#34;); print(\u0026#34;Accessing element: \u0026#34;); print(@array[1]); print(\u0026#34;\\n\u0026#34;); print(\u0026#34;Accessing element (mostly equivalent to above): \u0026#34;); print($array[1]); print(\u0026#34;\\n\u0026#34;); print(\u0026#34;Index of the last element: \u0026#34;); print($#array); print(\u0026#34;\\n\u0026#34;); print(\u0026#34;Slicing using \\@: \u0026#34;); print(@array[0, 1]); print(@array[0..$#array]); print(\u0026#34;\\n\u0026#34;); print(\u0026#34;Slicing using \\$: \u0026#34;); print($array[0, 1]); print($array[0..$#array]); print(\u0026#34;\\n\u0026#34;); Accessing element: bar Accessing element (mostly equivalent to above): bar Index of the last element: 2 Slicing using @: foobarfoobarbaz Slicing using $: barbar Some common array functions.\nmy @array = (3, 1, 2); my @sorted_array = sort(@array); my @reversed_array = reverse(@array); Hash Denoted by % sigil.\nThere are two different ways to initialize the hash variable. One is like array style and the other is more obivious to construct with pairs.\nmy %hash = (\u0026#34;key1\u0026#34;, \u0026#34;value1\u0026#34;, \u0026#34;key2\u0026#34;, \u0026#34;value2\u0026#34;); my %hash1 = (\u0026#34;key1\u0026#34; =\u0026gt; \u0026#34;value1\u0026#34;, \u0026#34;key2\u0026#34; =\u0026gt; \u0026#34;value2\u0026#34;); When it comes to access, one can use either $ or % just like array above. $ implies scalar, which is the value here, while % can access the pair.\nmy %hash = (\u0026#34;key1\u0026#34; =\u0026gt; \u0026#34;value1\u0026#34;, \u0026#34;key2\u0026#34; =\u0026gt; \u0026#34;value2\u0026#34;); print(\u0026#34;Accessing pair: \u0026#34;); print(%hash{\u0026#34;key1\u0026#34;}); print(\u0026#34;\\n\u0026#34;); print(\u0026#34;Accessing value: \u0026#34;); print($hash{\u0026#34;key1\u0026#34;}); print(\u0026#34;\\n\u0026#34;); Accessing pair: key1value1 Accessing value: value1 Get keys and values.\nmy %hash = (\u0026#34;key1\u0026#34; =\u0026gt; \u0026#34;value1\u0026#34;, \u0026#34;key2\u0026#34; =\u0026gt; \u0026#34;value2\u0026#34;); my @keys = keys(%hash); my @values = values(%hash); Subroutine (Function) Subroutines in Perl just like shell functions where the parameter can be omitted and accessed by the default array @_.\nTo invoke a subroutine, use either foo 1, 2, 3; or foo(1, 2, 3) (preferred). Note that the former one needs comma to delimit arguments (not space!)\nsub foo { # Not preferred # my $para1 = @_[0], $para2 = @_[1]; my ($para1, $para2) = @_; print(\u0026#34;Parameter1: $para1, Parameter2: $para2\u0026#34;); } foo(\u0026#34;hello\u0026#34;, \u0026#34;world\u0026#34;); Parameter1: hello, Parameter2: world The subroutines can actually be defined with explicit parameters so that the number of parameters will be checked.\nuse 5.36.0; # or # use feature \u0026#39;signatures\u0026#39;; sub foo($a, $b) { return $a + $b; } print(foo(1, 2)); 3 Variadic parameter is also supported.\nuse 5.36.0; # or # use feature \u0026#39;signatures\u0026#39;; sub foo($a, $b, @c) { my $sum = $a + $b; for (@c) { $sum += $_; } return $sum; } print(foo(1, 2, 3..10)); 55 In Perl 5, a new syntax was introduced, where the subroutine can be invoked with a \u0026amp; prefix, like \u0026amp;foo(1, 2, 3). This syntax can be ignored in most cases since it doesn\u0026rsquo;t bring much benefit but confusion. A noticeable difference is with this syntax the subroutine can access caller\u0026rsquo;s @_.\nsub foo { print(\u0026#34;aha @_\\n\u0026#34;); } @_ = (\u0026#34;foo\u0026#34;, \u0026#34;bar\u0026#34;); foo; foo(); \u0026amp;foo; \u0026amp;foo(); aha aha aha foo bar aha Referencing Use \\ to reference a variable/subroutine.\nNote that on the binder end (the test subroutine), the reference variables must be scalars (because they references which make sense). For the function call, the -\u0026gt; operator is used to dereference (similar with C).\n$scalar = \u0026#34;foo\u0026#34;; @array = (1, 2, 3); %hash = (foo =\u0026gt; \u0026#34;foo1\u0026#34;, bar =\u0026gt; \u0026#34;bar1\u0026#34;); sub func { print(\u0026#34;called func\u0026#34;); } sub test { my ($s, $aref, $href, $fref) = @_; print(\u0026#34;Scalar: $s\u0026#34;); print(\u0026#34;\\nArray: \u0026#34;); print(\u0026#34;$_, \u0026#34;) for @$aref; print(\u0026#34;\\nHash: \u0026#34;); print(\u0026#34;$_ =\u0026gt; $hash{$_}, \u0026#34;) for keys %$href; print(\u0026#34;\\n\u0026#34;); $fref-\u0026gt;(); } test $scalar, \\@array, \\%hash, \\\u0026amp;func; Scalar: foo Array: 1, 2, 3, Hash: foo =\u0026gt; foo1, bar =\u0026gt; bar1, called func Also note that array and hash variables must be passed by reference if they are intended to be used as it. Otherwise they will be slurped into the positional parameters.\nsub want_array { my ($a, $bref) = @_; print(\u0026#34;Parameter a is: $a\u0026#34;); print(\u0026#34;\\nArray ref is: $bref\u0026#34;); print(\u0026#34;\\nThe rest: \u0026#34;); print(\u0026#34;$_, \u0026#34;) for @_; print(\u0026#34;\\n\u0026#34;); } my @array = (1, 2, 3); print(\u0026#34;Passing by refenrence\\n\u0026#34;); want_array(\u0026#34;foo\u0026#34;, \\@array); print(\u0026#34;Passing by value\\n\u0026#34;); want_array(\u0026#34;foo\u0026#34;, @array); Passing by refenrence Parameter a is: foo Array ref is: ARRAY(0x2019140) The rest: foo, ARRAY(0x2019140), Passing by value Parameter a is: foo Array ref is: 1 The rest: foo, 1, 2, 3, Anonymous Anonymous array The anonymous array construction returns a reference. Note the square brackets [] are used here.\nmy $aref = [1, 2, 3]; print(\u0026#34;$_, \u0026#34;) for @$aref; 1, 2, 3, Anonymous hash The anonymous hash construction returns a reference. Note the curly brackets {} are used here.\nmy $href = { foo =\u0026gt; \u0026#34;foovalue\u0026#34;, bar =\u0026gt; \u0026#34;barvalue\u0026#34; }; while (my ($k, $v) = each %$href) { print(\u0026#34;$k =\u0026gt; $v, \u0026#34;); } foo =\u0026gt; foovalue, bar =\u0026gt; barvalue, Anonymous subroutine The anonymous subroutine construction returns a reference. Note no name is specified here and -\u0026gt; operator are used to invoke the call.\nmy $sref = sub { print(\u0026#34;Called subroutine @_[0]\u0026#34;); }; $sref-\u0026gt;(\u0026#34;wow\u0026#34;); Called subroutine wow Lexical binding Use keyword my.\nmy $foo = \u0026#34;foo\u0026#34;; { my $foo = \u0026#34;FOO\u0026#34;; print(\u0026#34;Inside: $foo\\n\u0026#34;); } print($foo); print(\u0026#34;outside: $foo\\n\u0026#34;); Inside: FOO foooutside: foo Variable shadowing Use keyword local.\nsub foo { print(\u0026#34;In foo: $bar\\n\u0026#34;); # Access a free variable } $bar = \u0026#34;bar\u0026#34;; { local $bar = \u0026#34;BAR\u0026#34;; print(\u0026#34;In block: $bar\\n\u0026#34;); foo($bar); } print(\u0026#34;Out of block: $bar\\n\u0026#34;); foo($bar); In block: BAR In foo: BAR Out of block: bar In foo: bar String interpolation Similar with shell scripts.\nmy $foo = \u0026#34;foo\u0026#34;, $bar = \u0026#34;bar\u0026#34;; print(\u0026#34;Hello $foo $bar! Hey ${foo}-${bar}\\n\u0026#34;); Hello foo bar! Hey foo-bar Expression Statement modifiers.\nif EXPR unless EXPR while EXPR until EXPR for LIST foreach LIST when EXPR Arithmetic\n+ addition - subtraction * multiplication / division Numeric comparison\n== equality != inequality \u0026lt; less than \u0026gt; greater than \u0026lt;= less than or equal \u0026gt;= greater than or equal String comparison\neq equality ne inequality lt less than gt greater than le less than or equal ge greater than or equal Boolean logic\n\u0026amp;\u0026amp; and || or ! not Boolean logic (with much lower precedence)\nand or not Miscellaneous\n= assignment . string concatenation x string multiplication (repeats strings) .. range operator (creates a list of numbers or strings) Statement Commonly used compound statements like if, for, and while have the same usage like C.\nWorth noting that the continue indicates the block of code will be executed every time before the loop condition is updated, even the iteration is skipped via next statement.\nif (EXPR) BLOCK if (EXPR) BLOCK else BLOCK if (EXPR) BLOCK elsif (EXPR) BLOCK ... if (EXPR) BLOCK elsif (EXPR) BLOCK ... else BLOCK unless (EXPR) BLOCK unless (EXPR) BLOCK else BLOCK unless (EXPR) BLOCK elsif (EXPR) BLOCK ... unless (EXPR) BLOCK elsif (EXPR) BLOCK ... else BLOCK given (EXPR) BLOCK LABEL while (EXPR) BLOCK LABEL while (EXPR) BLOCK continue BLOCK LABEL until (EXPR) BLOCK LABEL until (EXPR) BLOCK continue BLOCK LABEL for (EXPR; EXPR; EXPR) BLOCK LABEL for VAR (LIST) BLOCK LABEL for VAR (LIST) BLOCK continue BLOCK LABEL foreach (EXPR; EXPR; EXPR) BLOCK LABEL foreach VAR (LIST) BLOCK LABEL foreach VAR (LIST) BLOCK continue BLOCK LABEL BLOCK LABEL BLOCK continue BLOCK PHASE BLOCK As of Perl 5.36, you can iterate over multiple values at a time by specifying a list of lexicals within parentheses:\nno warnings \u0026#34;experimental::for_list\u0026#34;; LABEL for my (VAR, VAR) (LIST) BLOCK LABEL for my (VAR, VAR) (LIST) BLOCK continue BLOCK LABEL foreach my (VAR, VAR) (LIST) BLOCK LABEL foreach my (VAR, VAR) (LIST) BLOCK continue BLOCK If enabled by the experimental try feature, the following may also be used:\ntry BLOCK catch (VAR) BLOCK try BLOCK catch (VAR) BLOCK finally BLOCK Quoting Customary Generic Meaning Interpolates '' q{} Literal no \u0026quot;\u0026quot; qq{} Literal yes `` qx{} Command yes* qw{} Word list no // m{} Pattern match yes* qr{} Pattern yes* s{}{} Substitution yes* tr{}{} Transliteration no (but see below) y{}{} Transliteration no (but see below) EOF here-doc yes* Note: * unless the delimiter is \u0026lsquo;\u0026rsquo;.\n","permalink":"https://peromage.github.io/p/perl-quick-reference/","tags":["perl","linux","text_processing"],"title":"Perl Quick Reference"},{"categories":["linux"],"contents":"I\u0026rsquo;ve been learning Nix for a while and using the Nix package manager on my work desktop that runs Ubuntu. However, I did not use the NixOS on my personal laptop because I thought I might put a lot effort after work to set it up, which I didn\u0026rsquo;t really want to. Until recent, the Arch dependencies broke again and I felt it kinda suck to fix those issues so I decided to give Nix a try. To my suprise, the installation process is way simpler than I expected.\nIn this post, I\u0026rsquo;m going to put the miniaml intial setup of NixOS on my laptop. The complete tweaks may come up a little later because I\u0026rsquo;m still playing around with it.\nNote that, my setup is based on btrfs and luks. And the NixOS version used at the time writing this post is 23.05.\nSet up partition Since I have this set up already and I don\u0026rsquo;t want to wipe my entire disk, the filesystem and encryption setup parts are skipped. However, the Arch documents are still viable for Nix.\nBtrfs\nLuks\n# Decrypt the disk cryptsetup open /dev/nvme0n1p2 ffroot # Mount btrfs root to prepare subvolumes mount /dev/mapper/ffroot /mnt cd /mnt btrfs subvolume create @nixos btrfs subvolume create @nixstore btrfs subvolume create @home btrfs subvolume create @swap chattr +C @swap btrfs subvolume create @vm chattr +C @vm # Mount NixOS root and other partitions umount /mnt mount -o subvol=@nixos,noatime,ssd,compress=zstd:3 /dev/mapper/ffroot /mnt cd /mnt mkdir nix mkdir home mkdir ffstore mkdir ffstore/swap mkdir ffstore/vm mkdir boot mount -o subvol=@nixstore,noatime,ssd,compress=zstd:3 /dev/mapper/ffroot /mnt/nix mount -o subvol=@home,noatime,ssd,compress=zstd:3 /dev/mapper/ffroot /mnt/home mount -o subvol=@swap,noatime,ssd,compress=zstd:3 /dev/mapper/ffroot /mnt/ffstore/swap mount -o subvol=@vm,noatime,ssd,compress=zstd:3 /dev/mapper/ffroot /mnt/ffstore/vm mount /dev/nvme0n1p1 /mnt/boot Initialize the system config Just one command. The generated config files will be located under /etc/nixos/.\nnixos-generate-config --root /mnt Edit the system config For the hardware config nothing really needs to be changed. Nix is amazing that it has all the stuff ready to go including configuring the decryption on startup!\nOnly two minor changes that needs to be made. One is the subvolume mount options. For some reasons it doesn\u0026rsquo;t have all the options that we used to mount. The other one is the swap file.\n# Do not modify this file! It was generated by ‘nixos-generate-config’ # and may be overwritten by future invocations. Please make changes # to /etc/nixos/configuration.nix instead. { config, lib, pkgs, modulesPath, ... }: { imports = [ (modulesPath + \u0026#34;/installer/scan/not-detected.nix\u0026#34;) ]; boot.initrd.availableKernelModules = [ \u0026#34;xhci_pci\u0026#34; \u0026#34;thunderbolt\u0026#34; \u0026#34;nvme\u0026#34; \u0026#34;usb_storage\u0026#34; \u0026#34;sd_mod\u0026#34; ]; boot.initrd.kernelModules = [ ]; boot.kernelModules = [ \u0026#34;kvm-intel\u0026#34; ]; boot.extraModulePackages = [ ]; fileSystems.\u0026#34;/\u0026#34; = { device = \u0026#34;/dev/disk/by-uuid/35154f6e-27aa-49f8-b1b6-6472127cb524\u0026#34;; fsType = \u0026#34;btrfs\u0026#34;; options = [ \u0026#34;subvol=@nixos\u0026#34; \u0026#34;ssd\u0026#34; \u0026#34;noatime\u0026#34; \u0026#34;compress=zstd:3\u0026#34; ]; }; boot.initrd.luks.devices.\u0026#34;ffroot\u0026#34;.device = \u0026#34;/dev/disk/by-uuid/d698d7a5-125f-46ad-bc1d-47f9807afdef\u0026#34;; fileSystems.\u0026#34;/nix\u0026#34; = { device = \u0026#34;/dev/disk/by-uuid/35154f6e-27aa-49f8-b1b6-6472127cb524\u0026#34;; fsType = \u0026#34;btrfs\u0026#34;; options = [ \u0026#34;subvol=@nixstore\u0026#34; \u0026#34;ssd\u0026#34; \u0026#34;noatime\u0026#34; \u0026#34;compress=zstd:3\u0026#34; ]; }; fileSystems.\u0026#34;/home\u0026#34; = { device = \u0026#34;/dev/disk/by-uuid/35154f6e-27aa-49f8-b1b6-6472127cb524\u0026#34;; fsType = \u0026#34;btrfs\u0026#34;; options = [ \u0026#34;subvol=@home\u0026#34; \u0026#34;ssd\u0026#34; \u0026#34;noatime\u0026#34; \u0026#34;compress=zstd:3\u0026#34; ]; }; fileSystems.\u0026#34;/boot\u0026#34; = { device = \u0026#34;/dev/disk/by-uuid/8F86-D998\u0026#34;; fsType = \u0026#34;vfat\u0026#34;; }; fileSystems.\u0026#34;/ffstore/swap\u0026#34; = { device = \u0026#34;/dev/disk/by-uuid/35154f6e-27aa-49f8-b1b6-6472127cb524\u0026#34;; fsType = \u0026#34;btrfs\u0026#34;; options = [ \u0026#34;subvol=@swap\u0026#34; \u0026#34;ssd\u0026#34; \u0026#34;noatime\u0026#34; \u0026#34;compress=zstd:3\u0026#34; ]; }; fileSystems.\u0026#34;/ffstore/vm\u0026#34; = { device = \u0026#34;/dev/disk/by-uuid/35154f6e-27aa-49f8-b1b6-6472127cb524\u0026#34;; fsType = \u0026#34;btrfs\u0026#34;; options = [ \u0026#34;subvol=@vm\u0026#34; \u0026#34;ssd\u0026#34; \u0026#34;noatime\u0026#34; \u0026#34;compress=zstd:3\u0026#34; ]; }; swapDevices = [ { device = \u0026#34;/ffstore/swap/swap32gb.img\u0026#34;; } ]; # Enables DHCP on each ethernet and wireless interface. In case of scripted networking # (the default) this is the recommended approach. When using systemd-networkd it\u0026#39;s # still possible to use this option, but it\u0026#39;s recommended to use it in conjunction # with explicit per-interface declarations with `networking.interfaces.\u0026lt;interface\u0026gt;.useDHCP`. networking.useDHCP = lib.mkDefault true; # networking.interfaces.wlp166s0.useDHCP = lib.mkDefault true; nixpkgs.hostPlatform = lib.mkDefault \u0026#34;x86_64-linux\u0026#34;; powerManagement.cpuFreqGovernor = lib.mkDefault \u0026#34;powersave\u0026#34;; hardware.cpu.intel.updateMicrocode = lib.mkDefault config.hardware.enableRedistributableFirmware; } For the system config, just enable whatever we need.\n# Edit this configuration file to define what should be installed on # your system. Help is available in the configuration.nix(5) man page # and in the NixOS manual (accessible by running `nixos-help`). { config, pkgs, ... }: { imports = [ # Include the results of the hardware scan. ./hardware-configuration.nix ]; # Use the systemd-boot EFI boot loader. boot.loader.systemd-boot.enable = true; boot.loader.efi.canTouchEfiVariables = true; networking.hostName = \u0026#34;potpie\u0026#34;; # Define your hostname. # Pick only one of the below networking options. # networking.wireless.enable = true; # Enables wireless support via wpa_supplicant. networking.networkmanager.enable = true; # Easiest to use and most distros use this by default. # Set your time zone. time.timeZone = \u0026#34;America/Detroit\u0026#34;; # Configure network proxy if necessary # networking.proxy.default = \u0026#34;http://user:password@proxy:port/\u0026#34;; # networking.proxy.noProxy = \u0026#34;127.0.0.1,localhost,internal.domain\u0026#34;; # Select internationalisation properties. i18n.defaultLocale = \u0026#34;en_US.UTF-8\u0026#34;; console = { font = \u0026#34;Lat2-Terminus16\u0026#34;; # keyMap = \u0026#34;us\u0026#34;; useXkbConfig = true; # use xkbOptions in tty. }; # Enable the X11 windowing system. services.xserver.enable = true; # Enable the GNOME Desktop Environment. services.xserver.displayManager.gdm.enable = true; services.xserver.desktopManager.gnome.enable = true; # Configure keymap in X11 # services.xserver.layout = \u0026#34;us\u0026#34;; # services.xserver.xkbOptions = \u0026#34;eurosign:e,caps:escape\u0026#34;; # Enable CUPS to print documents. services.printing.enable = true; # Enable sound. sound.enable = true; hardware.pulseaudio.enable = true; # Enable touchpad support (enabled default in most desktopManager). services.xserver.libinput.enable = true; # Define a user account. Don\u0026#39;t forget to set a password with ‘passwd’. users.users.fang = { isNormalUser = true; extraGroups = [ \u0026#34;wheel\u0026#34; ]; # Enable ‘sudo’ for the user. uid = 1001; packages = with pkgs; [ firefox tree emacs29 git ]; }; # List packages installed in system profile. To search, run: # $ nix search wget environment.systemPackages = with pkgs; [ vim # Do not forget to add an editor to edit configuration.nix! The Nano editor is also installed by default. wget coreutils ]; # Some programs need SUID wrappers, can be configured further or are # started in user sessions. # programs.mtr.enable = true; programs.gnupg.agent = { enable = true; enableSSHSupport = true; }; # List services that you want to enable: # Enable the OpenSSH daemon. services.openssh.enable = true; # Open ports in the firewall. # networking.firewall.allowedTCPPorts = [ ... ]; # networking.firewall.allowedUDPPorts = [ ... ]; # Or disable the firewall altogether. networking.firewall.enable = true; # Copy the NixOS configuration file and link it from the resulting system # (/run/current-system/configuration.nix). This is useful in case you # accidentally delete configuration.nix. # system.copySystemConfiguration = true; # This value determines the NixOS release from which the default # settings for stateful data, like file locations and database versions # on your system were taken. It\u0026#39;s perfectly fine and recommended to leave # this value at the release version of the first install of this system. # Before changing this value read the documentation for this option # (e.g. man configuration.nix or on https://nixos.org/nixos/options.html). system.stateVersion = \u0026#34;23.05\u0026#34;; # Did you read the comment? } Build the system Finally let\u0026rsquo;s build our first NixOS.\nnixos-install And that\u0026rsquo;s it!\nIt was a blast that I\u0026rsquo;ve never seen such an elegant way to install a system. This is even simpler than Arch!\nNext up, secure boot, hibernation, the laptop specific fixes (functional keys)\u0026hellip; and Flakes! It must be a lot fun.\n","permalink":"https://peromage.github.io/p/moving-from-arch-linux-to-nixos/","tags":["arch_linux","nixos"],"title":"Moving from Arch Linux to NixOS"},{"categories":["tech"],"contents":"The information in this collection is from Internet, which is collected for my personal convenience.\nCSI sequences Code Name Effect CSI n A CUU – Cursor Up Moves the cursor n (default 1) cells in the given direction. If the cursor is already at the edge of the screen, this has no effect. CSI n B CUD – Cursor Down CSI n C CUF – Cursor Forward CSI n D CUB – Cursor Back CSI n E CNL – Cursor Next Line Moves cursor to beginning of the line n (default 1) lines down. (not ANSI.SYS) CSI n F CPL – Cursor Previous Line Moves cursor to beginning of the line n (default 1) lines up. (not ANSI.SYS) CSI n G CHA – Cursor Horizontal Absolute Moves the cursor to column n (default 1). (not ANSI.SYS) CSI n ; m H CUP – Cursor Position Moves the cursor to row n, column m. The values are 1-based, and default to 1 (top left corner) if omitted. A sequence such as CSI ;5H is a synonym for CSI 1;5H as well as CSI 17;H is the same as CSI 17H and CSI 17;1H CSI n J ED – Erase in Display Clears part of the screen. If n is 0 (or missing), clear from cursor to end of screen. If n is 1, clear from cursor to beginning of the screen. If n is 2, clear entire screen (and moves cursor to upper left on DOS ANSI.SYS). If n is 3, clear entire screen and delete all lines saved in the scrollback buffer (this feature was added for xterm and is supported by other terminal applications). CSI n K EL – Erase in Line Erases part of the line. If n is 0 (or missing), clear from cursor to the end of the line. If n is 1, clear from cursor to beginning of the line. If n is 2, clear entire line. Cursor position does not change. CSI n S SU – Scroll Up Scroll whole page up by n (default 1) lines. New lines are added at the bottom. (not ANSI.SYS) CSI n T SD – Scroll Down Scroll whole page down by n (default 1) lines. New lines are added at the top. (not ANSI.SYS) CSI n ; m f HVP – Horizontal Vertical Position Same as CUP CSI n m SGR – Select Graphic Rendition Sets the appearance of the following characters, see SGR parameters below. CSI 5i AUX Port On Enable aux serial port usually for local serial printer CSI 4i AUX Port Off Disable aux serial port usually for local serial printer CSI 6n DSR – Device Status Report Reports the cursor position (CPR) to the application as (as though typed at the keyboard) ESC[n;mR, where n is the row and m is the column.) CSI s SCP – Save Cursor Position Saves the cursor position/state. CSI u RCP – Restore Cursor Position Restores the cursor position/state. Some popular private sequences Code Effect CSI ? 25 h DECTCEM Shows the cursor, from the VT320. CSI ? 25 l DECTCEM Hides the cursor. CSI ? 1049 h Enable alternative screen buffer CSI ? 1049 l Disable alternative screen buffer CSI ? 2004 h Turn on bracketed paste mode. Text pasted into the terminal will be surrounded by ESC [200~ and ESC [201~, and characters in it should not be treated as commands (for example in Vim).[20] From Unix terminal emulators. CSI ? 2004 l Turn off bracketed paste mode. SGR parameters Code Effect Note 0 Reset / Normal all attributes off 1 Bold or increased intensity 2 Faint (decreased intensity) 3 Italic Not widely supported. Sometimes treated as inverse. 4 Underline 5 Slow Blink less than 150 per minute 6 Rapid Blink MS-DOS ANSI.SYS; 150+ per minute; not widely supported 7 reverse video swap foreground and background colors 8 Conceal Not widely supported. 9 Crossed-out Characters legible, but marked for deletion. 10 Primary(default) font 11–19 Alternative font Select alternative font {\\displaystyle n-10} {\\displaystyle n-10} 20 Fraktur Rarely supported 21 Doubly underline or Bold off Double-underline per ECMA-48.[22] See discussion 22 Normal color or intensity Neither bold nor faint 23 Not italic, not Fraktur 24 Underline off Not singly or doubly underlined 25 Blink off 27 Inverse off 28 Reveal conceal off 29 Not crossed out 30–37 Set foreground color See color table below 38 Set foreground color Next arguments are 5;n or 2;r;g;b, see below 39 Default foreground color implementation defined (according to standard) 40–47 Set background color See color table below 48 Set background color Next arguments are 5;n or 2;r;g;b, see below 49 Default background color implementation defined (according to standard) 51 Framed 52 Encircled 53 Overlined 54 Not framed or encircled 55 Not overlined 60 ideogram underline or right side line Rarely supported 61 ideogram double underline or double line on the right side Rarely supported 62 ideogram overline or left side line Rarely supported 63 ideogram double overline or double line on the left side Rarely supported 64 ideogram stress marking Rarely supported 65 ideogram attributes off reset the effects of all of 60–64 90–97 Set bright foreground color aixterm (not in standard) 100–107 Set bright background color aixterm (not in standard) Color code Color Foreground Background Black \\u001b[30m \\u001b[40m Red \\u001b[31m \\u001b[41m Green \\u001b[32m \\u001b[42m Yellow \\u001b[33m \\u001b[43m Blue \\u001b[34m \\u001b[44m Magenta \\u001b[35m \\u001b[45m Cyan \\u001b[36m \\u001b[46m White \\u001b[37m \\u001b[47m Bright Black \\u001b[30;1m \\u001b[40;1m Bright Red \\u001b[31;1m \\u001b[41;1m Bright Green \\u001b[32;1m \\u001b[42;1m Bright Yellow \\u001b[33;1m \\u001b[43;1m Bright Blue \\u001b[34;1m \\u001b[44;1m Bright Magenta \\u001b[35;1m \\u001b[45;1m Bright Cyan \\u001b[36;1m \\u001b[46;1m Bright White \\u001b[37;1m \\u001b[47;1m Reset \\u001b[0m \\u001b[0m ","permalink":"https://peromage.github.io/p/ansi-escape-code-collection/","tags":["ansi","escape_code","terminal"],"title":"ANSI Escape Code Collection"},{"categories":["tech"],"contents":"Boot from any ISO file\nHybrid UEFI GPT + BIOS MBR/GPT boot Preparation Create 3 partitions on a removable USB stick.\nA BIOS boot partition (gdisk type code EF02, or GUID 21686148-6449-6E6F-744E-656564454649) with no filesystem. This partition can be put in any place on the disk but it is recommended to put it at the begginning from sector 34 to 2047. At minimal 1 MiB. An EFI System partition (gdisk type code EF00) with a FAT32 filesystem. This partition can be as small as 50 MiB but it is better to set at least 256 MiB (550 MiB recommended). Data partition (use a filesystem supported by GRUB). This partition can take up the rest of the space of the drive. GRUB Installation Mount EFI and data partitions. First install GRUB for UEFI:\n# grub-install --target=x86_64-efi --recheck --removable --efi-directory=/EFI_MOUNTPOINT --boot-directory=/DATA_MOUNTPOINT/boot Then GRUB for BIOS:\n# grub-install --target=i386-pc --recheck --boot-directory=/DATA_MOUNTPOINT/boot /dev/sdX As an additional fallback, GRUB on the MBR-bootable data partition can be installed:\n# grub-install --target=i386-pc --recheck --boot-directory=/DATA_MOUNTPOINT/boot /dev/sdX3 GRUB Configuration Using a Template There are some git projects which provide some pre-existing GRUB configuration files, and a nice generic grub.cfg which can be used to load the other boot entries on demand, showing them only if the specified ISO files - or folders containing them - are present on the drive. Multiboot USB GLIM (GRUB2 Live ISO Multiboot)\nUsing Manual Configuration Install memdisk module from Syslinux: # cp /usr/lib/syslinux/bios/memdisk /DATA_MOUNTPOINT/boot/ Finding the partition where image files are located by persistent name is recommended. To get this done by using either filesystem UUID or partition label (this step is not necessarily required due to iso files are located on the same partition).\nA template configuration can be found below. Note: /DATA_MOUNTPOINT/boot/ is for GRUB boot files and /DATA_MOUNTPOINT/iso/ is for images. Those directories can be variant.\n#/DATA_MOUNTPOINT/boot/grub/grub.cfg ## insert modules # if on ntfs with compression on #insmode ntfscomp ## path variables set isopath=${root}/iso set memdisk=${prefix}/memdisk # path to the partition holding ISO images (using UUID) #probe -u $root --set=rootuuid #set imgdevpath=\u0026#34;/dev/disk/by-uuid/$rootuuid\u0026#34; # path to the partition holding ISO images (using UUID explicitly) #set imgdevpath=\u0026#34;/dev/disk/by-uuid/UUID_value # path to the partition holding ISO images (using UUID searching) #search --set=imgdevpath --no-floppy --fs-uuid UUID_value # path to the partition holding ISO images (using labels) #set imgdevpath=\u0026#34;/dev/disk/by-label/label_value\u0026#34; # path to the partition holding ISO images (using file searching) #search --set=part --no-floppy --file PATH_TO_FILE menuentry \u0026#34;Generic ISO Boot Menu\u0026#34; { linux16 ${memdisk} iso ro initrd16 ${isopath}/PATH_TO_ISO } References BIOS + GPT + GRUB + Linux + Windows 折腾笔记 Arch Linux Wiki: GRUB Arch Linux Wiki: EFI system partition Arch Linux Wiki: Multiboot USB drive Wiki: GUID Partition Table\n","permalink":"https://peromage.github.io/p/archive-multiboot-usb/","tags":["multi_boot","usb_drive"],"title":"[Archive] Multiboot USB"},{"categories":["emacs"],"contents":"This post mainly helps myself remember how to quickly write a major mode. My memory is getting worse. So sad. :(\nUse define-derived-mode Doc: https://www.gnu.org/software/emacs/manual/html_node/elisp/Derived-Modes.html\nThis perhaps the most common way to write a major mode.\nMost of the times I derive from fundamental-mode, or nil if the parent mode is not needed (a brand new mode).\n;; With a parent mode (define-derived-mode foo-mode fundamental-mode \u0026#34;Foo\u0026#34; (do something)) ;; Or nothing (define-derived-mode foo-mode nil \u0026#34;Foo\u0026#34; (do something)) Here is the common pattern that I use. I use :after-hook keyword to run some additional setups after the major mode call. This is useful if some of the settings need to be overridden from the parent mode settings or its hooks.\n(define-derived-mode long-log-mode so-long-mode \u0026#34;LongLog\u0026#34; \u0026#34;A major mode used for large text files. Based on `so-long-mode\u0026#39;. Buffers with this mode enabled are read-only by default.\u0026#34; :interactive t :after-hook ;; Override the settings by `so-long-mode\u0026#39; (progn (toggle-truncate-lines 1) (hl-line-mode 1)) ;; `long-log-mode\u0026#39; settings start from here (add-to-list \u0026#39;so-long-minor-modes \u0026#39;line-number-mode) (read-only-mode 1)) Note: The parent mode hooks will be executed anyway even if delay-mode-hooks is used in the body. To avoid this, see Use defun.\nUse define-generic-mode Doc: https://www.gnu.org/software/emacs/manual/html_node/elisp/Generic-Modes.html\nThis is useful when I need a major mode with some syntax highlights. Quick and dirty.\nThe third argument keyword-list is a shorthand which will be highlighted with font-lock-keyword-face. It is equivalent to using the forth argument font-lock-list and setting it there. For more information about font lock, see here.\n;; This example is taken from EmacsWiki: https://www.emacswiki.org/emacs/GenericMode (define-generic-mode \u0026#39;foo-mode ;; name of the mode to create \u0026#39;(\u0026#34;!!\u0026#34;) ;; comments start with \u0026#39;!!\u0026#39; \u0026#39;(\u0026#34;account\u0026#34; \u0026#34;user\u0026#34; \u0026#34;password\u0026#34;) ;; some keywords \u0026#39;((\u0026#34;=\u0026#34; . \u0026#39;font-lock-operator) ;; \u0026#39;=\u0026#39; is an operator (\u0026#34;;\u0026#34; . \u0026#39;font-lock-builtin)) ;; \u0026#39;;\u0026#39; is a built-in \u0026#39;(\u0026#34;\\\\.foo$\u0026#34;) ;; files for which to activate this mode nil ;; other functions to call \u0026#34;A mode for foo files\u0026#34; ;; doc string for this mode ) Note: Any major mode hook will be executed anyway even if delay-mode-hooks is used in the last function list. To avoid this, see Use defun.\nUse defun Sometimes I just want to use the syntax table and font locks from a major mode but don\u0026rsquo;t want to invoke any hooks from it, LSP per say. Using define-derived-mode or define-generic-mode will not work since the major mode hooks will be called anyway at the end of major mode call (this is default behavior defined in those macro). However, we can simply define a function and use delay-mode-hooks to bypass this restriction.\nA pattern that I commonly use.\n(defun foo-mode () (interactive) (delay-mode-hooks (python-mode)) ;; Use the parent major mode except the hooks (setq mode-name \u0026#34;Foo\u0026#34;) ;; Don\u0026#39;t forget the name your mode (setq major-mode #\u0026#39;foo-mode) ;; Don\u0026#39;t forget the major mode symbol (setq-local indent-tabs-mode nil) (setq-local tab-width 4)) Happy hacking!\n","permalink":"https://peromage.github.io/p/different-ways-to-write-a-major-mode/","tags":["emacs","elisp"],"title":"Different Ways to Write a Major Mode"},{"categories":["coding"],"contents":"Update on \u0026lt;2023-06-07 Wed\u0026gt; Found a much easier way to configure this and tried again with the update-to-date lsp-java and it worked magically. Can\u0026rsquo;t recall why I had configuration issues before.\nSimply it would be:\nMake sure JDK 17 is installed (According to the requirement of lsp-java). Create a lib folder and put .jar files into it (or symlinks). See this issue. Run lsp-restart-workspace. Voila! Now LSP works as you would expect :).\nBackground As a Java newbie I found that Java setup is quite different from C++.\nInitially I added lsp-java along with the existing lsp-mode I\u0026rsquo;ve been using. With zero configuration it seemed to work fine. Completion is well supported for Java built-in libraries. However, when I tried visiting some symbols from some other places in the project that I\u0026rsquo;m working on, say JUnit, things getting complicated.\nIn C++\u0026rsquo;s world, with clangd, I can easily write a compile_flags.txt file and paste dependency header paths in it. But in Java, the code is organized as one big project and they are linked together in a \u0026ldquo;workspace\u0026rdquo;. I believe this is a concept from Eclipse. It doesn\u0026rsquo;t work like C++ where all your projects are loosely coupled and only bundled together during compile time. That\u0026rsquo;s why you can write compile_flags.txt for arbitrary projects because basically you\u0026rsquo;re writing compiler options.\nSo, how to make LSP work with external dependencies without copying them to the current working project. I searched a lot but it seemed like no one had discussed this problem. Maybe this is a very fundamental knowledge that every Java developer should know and not worth discussing. As a Java newbie, this really made me crazy. However, after several experiments it turned rather easy than I thought.\nSolution The lsp-java uses eclipse.jdt.ls as the LSP service provider. Whenever a project is opened, it creates a workspace folder under ~/.emacs.d/workspace.\nFor example, I have a project called awesome_app. When I open it in Emacs, lsp-java creates ~/.emacs.d/workspace/awesome_app_69131352 directory for me.\ntree -a -L 3 awesome_app_69131352/ ├── bin │ ├── com │ │ └── awesome ├── .classpath ├── .project └── .settings ├── org.eclipse.core.resources.prefs └── org.eclipse.jdt.core.prefs In the bin directory it caches all class files. Normally those files are stored in the project\u0026rsquo;s root directory along with the .classpath and .project files if it is opened by Eclipse. lsp-java configures it separately by default. I feel it kind neat and I like it.\nTo add other dependencies, simply modify the .classpath and .project.\nBy default, .project only contains the awesome_app project. The external dependencies need to be added under \u0026lt;linkedResources\u0026gt; section. It will look like this after modifications.\nNote that the \u0026lt;type\u0026gt; should be 2 if this is a directory. Otherwise 1 for files. Details can be found in Eclipse document.\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;projectDescription\u0026gt; \u0026lt;name\u0026gt;awesome_app_69131352\u0026lt;/name\u0026gt; \u0026lt;comment\u0026gt;\u0026lt;/comment\u0026gt; \u0026lt;projects\u0026gt; \u0026lt;/projects\u0026gt; \u0026lt;buildSpec\u0026gt; \u0026lt;buildCommand\u0026gt; \u0026lt;name\u0026gt;org.eclipse.jdt.core.javabuilder\u0026lt;/name\u0026gt; \u0026lt;arguments\u0026gt; \u0026lt;/arguments\u0026gt; \u0026lt;/buildCommand\u0026gt; \u0026lt;/buildSpec\u0026gt; \u0026lt;natures\u0026gt; \u0026lt;nature\u0026gt;org.eclipse.jdt.core.javanature\u0026lt;/nature\u0026gt; \u0026lt;/natures\u0026gt; \u0026lt;linkedResources\u0026gt; \u0026lt;link\u0026gt; \u0026lt;name\u0026gt;_\u0026lt;/name\u0026gt; \u0026lt;type\u0026gt;2\u0026lt;/type\u0026gt; \u0026lt;location\u0026gt;/home/fang/awesome_app\u0026lt;/location\u0026gt; \u0026lt;/link\u0026gt; \u0026lt;link\u0026gt; \u0026lt;name\u0026gt;junit\u0026lt;/name\u0026gt; \u0026lt;type\u0026gt;2\u0026lt;/type\u0026gt; \u0026lt;location\u0026gt;/home/fang/external/junit\u0026lt;/location\u0026gt; \u0026lt;/link\u0026gt; \u0026lt;link\u0026gt; \u0026lt;name\u0026gt;mockito\u0026lt;/name\u0026gt; \u0026lt;type\u0026gt;2\u0026lt;/type\u0026gt; \u0026lt;location\u0026gt;/home/fang/external/mockito\u0026lt;/location\u0026gt; \u0026lt;/link\u0026gt; \u0026lt;/linkedResources\u0026gt; \u0026lt;filteredResources\u0026gt; \u0026lt;filter\u0026gt; \u0026lt;id\u0026gt;1676757224502\u0026lt;/id\u0026gt; \u0026lt;name\u0026gt;\u0026lt;/name\u0026gt; \u0026lt;type\u0026gt;30\u0026lt;/type\u0026gt; \u0026lt;matcher\u0026gt; \u0026lt;id\u0026gt;org.eclipse.core.resources.regexFilterMatcher\u0026lt;/id\u0026gt; \u0026lt;arguments\u0026gt;node_modules|.metadata|archetype-resources|META-INF/maven|__CREATED_BY_JAVA_LANGUAGE_SERVER__\u0026lt;/arguments\u0026gt; \u0026lt;/matcher\u0026gt; \u0026lt;/filter\u0026gt; \u0026lt;/filteredResources\u0026gt; \u0026lt;/projectDescription\u0026gt; Then modify the .classpath file to let JDT server cache dependency class files.\nThe dependency\u0026rsquo;s kind should be src and path should be name/path/to/root/of/package. The name in path is the name we specified in the .project for this dependency and the relative path should be the root where package\u0026rsquo;s fully qualified name starts.\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;classpath\u0026gt; \u0026lt;classpathentry kind=\u0026#34;con\u0026#34; path=\u0026#34;org.eclipse.jdt.launching.JRE_CONTAINER\u0026#34;/\u0026gt; \u0026lt;classpathentry kind=\u0026#34;src\u0026#34; path=\u0026#34;_/src\u0026#34;/\u0026gt; \u0026lt;classpathentry kind=\u0026#34;src\u0026#34; path=\u0026#34;junit/src/main/java\u0026#34;/\u0026gt; \u0026lt;classpathentry kind=\u0026#34;src\u0026#34; path=\u0026#34;mockito/src/main/java\u0026#34;/\u0026gt; \u0026lt;classpathentry kind=\u0026#34;output\u0026#34; path=\u0026#34;bin\u0026#34;/\u0026gt; \u0026lt;/classpath\u0026gt; Lastly, restart LSP workspace and see if cached class files appear in bin directory. It should have something like this.\nawesome_app_69131352/ ├── bin │ ├── com │ │ └── awesome │ ├── junit │ │ ├── extensions │ │ ├── framework │ │ ├── runner │ │ └── textui │ └── org │ ├── junit │ └── mockito ├── .classpath ├── .project └── .settings ├── org.eclipse.core.resources.prefs └── org.eclipse.jdt.core.prefs Hooray!\n","permalink":"https://peromage.github.io/p/lsp-setup-for-java/","tags":["lsp","java","emacs","jdt"],"title":"LSP Setup for Java"},{"categories":null,"contents":"This website does not collect any data from you.\nHowever, this website is themed with Skeria which loads some external resources and scripts.\nIf you have concerns, please visit its home page for more information.\n","permalink":"https://peromage.github.io/privacy/","tags":null,"title":"Privacy Notice"},{"categories":null,"contents":"This website and its content are licensed under the GNU General Public License v3.0.\nThis website is built with Emacs, Org Mode, Hugo, ox-hugo and Skeria. Please refer to these projects\u0026rsquo; home page for licenses.\n","permalink":"https://peromage.github.io/license/","tags":null,"title":"License"},{"categories":["emacs"],"contents":"Background I previously wrote a post about managing blog posts with ox-hugo in org mode. I used to follow the recommendation to keep posts under org subtrees. As posts grew, I found that the opening speed is quite slow even I didn\u0026rsquo;t have many pictures inserted. Although managing the entire site within one file does have some convenience, the slowness is something I can\u0026rsquo;t bear.\nAlso I feel it a little awkward when I use the subtree style management. I always worried about if the format was correct like how many empty lines between posts or if something was accidentally changed outside of the post that I was editing. And in order to maintain the subtree structure, the actual posts have to be indented (nested), which is not what I like. There are solutions for this nested editing. I used to use org-narrow-to-subtree when I was editing the post and use widen to switch the view back. But still, I always worried about the format (please forgive OCD patient).\nHowever, I want to continue using ox-hugo. It is a wonderful package indeed! Luckily, it supports file-based style.\nGlobal properties One of the benefits that subtree style brings is you can inherit properties from the parent nodes. You can put category tags on the parent node. When creating posts under it, all posts will automatically inherit the category when they get exported. Also you can set some global org settings in the header so all posts can share it.\nI want to have as much as close to this goodies when I use file-based style I created a setup.conf file as the global settings.\n# -*- mode: org; -*- # setup.conf Author. #+author: John Doe On file open. #+startup: fold #+startup: indent #+startup: logdone #+startup: logdrawer Todo states. #+seq_todo: DRAFT(d) | CREATED(c!) PUBLISHED(p!) Categories. This is mainly for subtree-based export style. #+tags: @emacs @coding @linux @tech @ramble @折腾 Posts under categories are expected to read this so the path is relative to the post files. #+hugo_base_dir: ../../hugo Default section. #+hugo_section: blog Date and time. #+hugo_auto_set_lastmod: t #+options: d:t ... When starting a new post, simple use it as the setup file. The editing experience will be consistent. If some settings needs to be overridden in this post specifically, put them before the #+setupfile directive (same settings only the first occurrence gets applied).\n# new-post.org #+startup: nofold #+setupfile: ./setup.conf ... Something needs to be noticed is, as you can see, I\u0026rsquo;ve put some descriptions in the config file. Don\u0026rsquo;t worry. Only org directives will be read when used by #+setupfile. This is great because it gives you flexibility to keep comments of those settings in case you forget in the future.\nInherit category I also want to have the ability to inherit category so I don\u0026rsquo;t need to manually type it. Indeed I sometimes forget what categories I have if I don\u0026rsquo;t write blog for a while.\nTo achieve this, I created a few subfolders as categories and put posts under them respectively. Then I created another setup.conf under each category folder with the settings.\n# emacs/setup.conf #+hugo_categories: emacs #+setupfile: ../setup.conf Don\u0026rsquo;t doubt it. #+setupfile can be used recursively! Fantastic! Now new posts under emacs category just need to include this file in their headers and they will be assigned to this category automatically during export.\nHugo pages I actually use ox-hugo in a hybrid way. For navigation pages, I continue managing them with subtrees and overriding settings if it\u0026rsquo;s different from the global with heading properties.\nExport script I used to use a shell script to export. Just realized that Emacs had script support since version 22 so I created a Elisp script for this purpose.\nSimilar solution This can also be achieved by using Emacs local variable but it will ask you to confirm if those variables are safe if you don\u0026rsquo;t persist the settings. I find it quite annoying especially used with CI. It will most likely break CI if you are not careful.\nHowever, this is more convenience than the header method when you have nested folder structures. It can calculate the Hugo base path when the variables get evaluated.\n((org-mode . ((eval . (setq org-hugo-base-dir (locate-dominating-file default-directory \u0026#34;.git\u0026#34;)))))) Be careful when using it with CI.\nFolder structure My folder structure finally looks like this.\n. ├── coding │ ├── post1.org │ ├── post2.org │ ├── post3.org │ └── setup.conf ├── emacs │ ├── post1.org │ ├── post2.org │ ├── post3.org │ └── setup.conf ├── linux │ ├── post1.org │ ├── post2.org │ ├── post3.org │ └── setup.conf ├── tech │ ├── post1.org │ ├── post2.org │ ├── post3.org │ └── setup.conf ├── setup.conf ├── hugo-pages.org └── ox-hugo-export.el Summary Now I feel it much clearer. ox-hugo is a definitely a fantastic package. It helps me manage posts in org mode and seamlessly work with Hugo with ease.\nIf you haven\u0026rsquo;t used either org mode or Hugo, I highly recommend to give them a try.\n","permalink":"https://peromage.github.io/p/file-based-blog-management-with-ox-hugo/","tags":["emacs","org","ox-hugo","hugo"],"title":"File-based Blog Management with ox-hugo"},{"categories":["emacs"],"contents":"I found that there were few posts mentioning about using lisp-data files. However, it seems to be used widely in various packages.\nEmacs manumal has a very detailed description of how to read and write lisp objects. In this post I\u0026rsquo;ll mainly demonstrate one specific use case.\nRead from file The biggest challenge is to parse file content to Lisp lists. After a quick search with describe-function, read function is able to perfectly handle it in this case.\nSuppose we have a lisp-data file named mydata with the content below.\ncat \u0026lt;\u0026lt;EOF \u0026gt;\u0026gt;mydata ;;; mydata -*- lisp-data -*- ((\u0026#34;~/repo/peromage.github.io/\u0026#34;) (\u0026#34;~/.emacs.d/\u0026#34;) (\u0026#34;~/some/random/place\u0026#34;)) EOF When we read it, we should read the whole file as a string first and then pass it to read function. The easiest way is to use with-temp-buffer.\n(setq data (read (with-temp-buffer (insert-file-contents \u0026#34;mydata\u0026#34;) (buffer-string)))) (print data) (print (nth 1 data)) ((\u0026#34;~/repo/peromage.github.io/\u0026#34;) (\u0026#34;~/.emacs.d/\u0026#34;) (\u0026#34;~/some/random/place\u0026#34;)) (\u0026#34;~/.emacs.d/\u0026#34;) Write to file Opposite to read, to write to file in format that read understands, use print or prin1. Unlike princ which outputs something that human readable, like removing double quotes for string, these two functions will keep the original data format.\nSuppose there is a list that we want to save to a file.\n(setq data \u0026#39;((\u0026#34;foo\u0026#34;) (\u0026#34;bar\u0026#34;) (\u0026#34;baz\u0026#34;))) To write to a file.\n(with-temp-file \u0026#34;saved_data\u0026#34; (insert \u0026#34;;;; saved_data -*- lisp-data -*-\\n\u0026#34;) (print data (current-buffer))) Check the out file.\ncat saved_data ;;; mydata -*- lisp-data -*- ((\u0026#34;foo\u0026#34;) (\u0026#34;bar\u0026#34;) (\u0026#34;baz\u0026#34;)) Nice.\n","permalink":"https://peromage.github.io/p/use-lisp-data-files-in-emacs/","tags":["emacs","elisp"],"title":"Use lisp-data Files in Emacs"},{"categories":["linux"],"contents":"I recently got my new laptop and I found that some additional tweaks need to be made for laptops. Thus, this post is to have a record in case I forget when I have to reinstall the system.\nSome basic setup Unlike desktop, laptops have to be secure so encrytion is a must.\nDetails of how-to can be found on Arch wiki. I\u0026rsquo;m not going to go through that here. However, I\u0026rsquo;ll note down some considerations and things that need to pay attention to.\nEncryption Arch wiki about encryption has very good examples.\nIn my case I use LUKS2. As for the scheme, I leave EFI partition unencrypted and encrypt the whole BTRFS partition (See Partitioning). EFI partition also acts as boot partition (ramfs and kernel reside inside). Reason to take this approach is encrypted boot partition makes things more complicated (Like you have to decrypt the partition twice. Once from bootloader and the other one from kernel). Plus I have secure boot enabled (see Secure boot) so unencrypted boot partition is not really a big problem.\nQuick setup.\n# cryptsetup -y -v luksFormat /dev/sda2 # cryptsetup open /dev/sda2 myroot A passphrase will be created to unlock the partition in slot 0.\nTo tell kernel to decrypt the disk on startup, ramfs and kernel parameters have to be updated. I prefer using systemd rather than busybox provided by udev. In this case sd-encrypt has to be added instead of encrypt\n# /etc/mkinitcpio.conf ... HOOKS=(base systemd autodetect keyboard modconf block sd-encrypt filesystems fsck) Then update kernel parameters to unlock and map the encrypted partition.\n# /boot/loader/entries/arch.conf ... options rd.luks.name=51d2be03-b9a4-4d4d-bc5a-0a9dba854c1f=ffroot root=/dev/mapper/ffroot Then we\u0026rsquo;re going to use TPM2 to automatically decrypt on bootup. For PCR see this help page.\n# systemd-cryptenroll /dev/sda2 --tpm2-device=auto --tpm2-pcrs=0+7 --tpm2-with-pin=true Alternatively you can use a more secure recovery key generated randomly instead of using your own passphrase. Assume the passphrase that was created previously is in slot 0.\n# systemd-cryptenroll /dev/sda2 --recovery-key # systemd-cryptenroll /dev/sda2 --wipe-slot=0 # systemd-cryptenroll /dev/sda2 --tpm2-device=auto --tpm2-pcrs=0+7 --tpm2-with-pin=true Note: It is important to keep at least a backup decryption method (recovery key or passphrase) when making modifications to slots. If only TPM slot left then you\u0026rsquo;re probably fucked up because you can no longer add or remove key slots. Once the boot is tampered you would not be able to recover anymore.\nPartitioning See Arch wiki about BTRFS to get to know how to setup BTRFS file system.\nUsing too many partitions is not good for SSD so I only have two partitions on the disk: EFI partition (also as boot) + a big partition formated with BTRFS. The second partition is encrypted, which will be demonstrated in the next topic.\nWith BTRFS, I can use subvolume to achieve the similar effect like what partition does, but it is more flexible.\nThese subvolumes are created under the big BTRFS\u0026rsquo;s root.\nSubvolume Mount Point Note @os-arch / System root @os-arch-var /var Avoid getting snapshot @home /home Separated home @swap /swap Swap files (no compression, no CoW) @snapshots /snapshots Snapshots Quick setup. Note that the swap subvolume should have no-COW flag.\n# mkfs.btrfs -L ffroot /dev/mapper/ffroot # mount /dev/mapper/ffroot /mnt # btrfs subvolume create /mnt/@os-arch # btrfs subvolume create /mnt/@os-arch-var # btrfs subvolume create /mnt/@home # btrfs subvolume create /mnt/@vm # btrfs subvolume create /mnt/@swap # chattr +C /mnt/@vm # chattr +C /mnt/@swap # btrfs subvolume create /mnt/@snapshots An example of how fstab is set up. For SSD, I also have discard=async enabled.\nAs for the compression, it seems to be enabled for the whole file system once one of the subvolume has it enabled. A workaround is to set the property by chattr +c. Based on the document statement, even if I don\u0026rsquo;t have compression option for the swap subvolume, it is enabled implicitly. The reason that I don\u0026rsquo;t want to use property-based compression option is that it cannot specify compression method. And btrfs property set \u0026lt;file\u0026gt; compression \u0026lt;zlib|lzo|zstd\u0026gt; seems to have some quirks.\nSo far I haven\u0026rsquo;t found any issues with this setup. Hope per-subvolume compression will be implemented soon.\n# \u0026lt;file system\u0026gt; \u0026lt;dir\u0026gt; \u0026lt;type\u0026gt; \u0026lt;options\u0026gt; \u0026lt;dump\u0026gt; \u0026lt;pass\u0026gt; # /dev/mapper/ffroot /dev/mapper/ffroot / btrfs rw,noatime,ssd,discard=async,space_cache=v2,compress=zstd:3,subvol=/@os-arch 0 1 # /dev/nvme0n1p1 LABEL=EFI_BOOT UUID=4652-2467 /boot vfat rw,relatime,fmask=0022,dmask=0022,codepage=437,iocharset=ascii,shortname=mixed,utf8,errors=remount-ro 0 2 # /dev/mapper/ffroot /dev/mapper/ffroot /var btrfs rw,noatime,ssd,discard=async,space_cache=v2,compress=zstd:3,subvol=/@os-arch-var 0 2 # /dev/mapper/ffroot /dev/mapper/ffroot /home btrfs rw,noatime,ssd,discard=async,space_cache=v2,compress=zstd:3,subvol=/@home 0 2 # /dev/mapper/ffroot /dev/mapper/ffroot /swap btrfs rw,noatime,ssd,discard=async,space_cache=v2,subvol=/@swap 0 2 # /dev/mapper/ffroot /dev/mapper/ffroot /vm btrfs rw,noatime,ssd,discard=async,space_cache=v2,subvol=/@vm 0 2 # swap files /swap/swap32gb.img none swap defaults 0 0 Snapshots Thanks to CoW feature provided by BTRFS, taking snapshots is easy.\nbtrfs subvolume snapshot source [dest/]name Read-only snapshot requires additional work when it gets restored. Usually I don\u0026rsquo;t use read-only argument when creating a snapshot.\nSecure boot Arch wiki has a very clear tutorial but eh. It\u0026rsquo;s too cumbersome. I choose to use sbctl to save my life.\nThe readme is very easy to follow but one thing needs to pay attention to is, grub doesn\u0026rsquo;t work with it. If you sign grub\u0026rsquo;s EFI file it will fail when secure boot is enforced. I switched to systemd-boot due to this reason. And I also find that systemd-boot is way easier to configure.\nFor a quick start.\n# sbctl status # sbctl create-keys # sbctl enroll-keys # sbctl status # sbctl sign -s /efi/EFI/BOOT/BOOTX64.EFI # sbctl sign -s /efi/EFI/systemd/systemd-bootx64.efi # sbctl sign -s /boot/vmlinuz-linux Use bundles (optional) Alternatively, you can also bundle kernel image and ramdisk image together as an EFI file.\n# sbctl bundle -s -i /boot/intel-ucode.img -k /boot/vmlinuz-linux -f /boot/initramfs-linux.img -c /proc/cmdline /boot/EFI/Linux/linux.efi # sbctl bundle -s -i /boot/intel-ucode.img -k /boot/vmlinuz-linux-zen -f /boot/initramfs-linux-zen.img -c /proc/cmdline /boot/EFI/Linux/linux-zen.efi Since the bundles are registered in sbctl\u0026rsquo;s database, the EFI files will be automatically re-generated when kernel is updated.\nHowever, in case if kernel parameter or ramdisk is updated, run this manually to re-generate new bundles.\n# sbctl generate-bundles Hibernation When creating swap files, keep in mind of the following:\nSwap files should NOT be set with CoW attribute on BTRFS file system. Use dd to ensure swap files don\u0026rsquo;t have holes. # chattr +C /mnt/@swap # dd if=/dev/zero of=/mnt/@swap/swapfile bs=1M count=8192 status=progress Then follow this wiki to calculate swap file physical offset on BTRFS partition.\nThen set kernel parameters. The UUID should be the UUID of decrypted BTRFS partition. Differentiate from the UUID above.\n# Kernel parameters ... resume=UUID=dcc33411-f4ae-46e0-ba7a-f285301b25f6 resume_offset=3420784 ... Update ramfs. Add resume hook.\nHOOKS=(base systemd autodetect keyboard modconf block sd-encrypt filesystems fsck resume) Overall kernel parameters Kernel parameters used for the previous sections include partitioning, encryption and hibernation.\ntitle Arch Liunx linux /vmlinuz-linux initrd /intel-ucode.img initrd /initramfs-linux.img options loglevel=4 quiet rw rd.luks.name=51d2be03-b9a4-4d4d-bc5a-0a9dba854c1f=ffroot root=/dev/mapper/ffroot rootflags=subvol=@arch-root mem_sleep_default=deep nvme.noacpi=1 module_blacklist=hid_sensor_hub resume=UUID=dcc33411-f4ae-46e0-ba7a-f285301b25f6 resume_offset=3420784 Installing Arch Linux I have a script to handle this: https://github.com/peromage/pew/blob/master/rice/setup-scripts/arch-install.sh\nPower management For power management, there are two options: TLP and power-profiles-daemon.\nTLP is powerful but it needs quite a bit attention to manually manage the configuration. And most of desktop environments don\u0026rsquo;t have integration with it by default.\npower-profiles-daemon can be used out of the box and desktop like KDE detects it automatically when it is installed.\nBoth power manager can only exist one at a time because they conflict with each other. You can mask one of them in systemd though. I don\u0026rsquo;t think that\u0026rsquo;s a good idea. To avoid scratching my head and save some hair, usually I use power-profiles-daemon.\nTLP My TLP preferences. Not too much. It might be a little aggressive since I want to have maximal battery life.\n# /etc/tlp.d/my-power-plan.conf TLP_DEFAULT_MODE=AC TLP_PERSISTENT_DEFAULT=0 CPU_SCALING_GOVERNOR_ON_AC=performance CPU_SCALING_GOVERNOR_ON_BAT=powersave CPU_ENERGY_PERF_POLICY_ON_AC=balance_performance CPU_ENERGY_PERF_POLICY_ON_BAT=balance_power CPU_MIN_PERF_ON_AC=0 CPU_MAX_PERF_ON_AC=100 CPU_MIN_PERF_ON_BAT=0 CPU_MAX_PERF_ON_BAT=20 CPU_BOOST_ON_AC=1 CPU_BOOST_ON_BAT=0 CPU_HWP_DYN_BOOST_ON_AC=1 CPU_HWP_DYN_BOOST_ON_BAT=0 SCHED_POWERSAVE_ON_AC=0 SCHED_POWERSAVE_ON_BAT=1 power-profiles-daemon No configuration needed. Just remember to enable the daemon service once it\u0026rsquo;s installed.\nHiDPI I previously used XFCE but now I\u0026rsquo;ve switched to KDE as the default desktop environment so HiDPI is not a problem anymore.\nFirefox scrolling with touchpad Yuck. Default scrolling experience on touchpad is just disgusting \u0026ndash; it lacks kinetic scrolling. This mostly because Firefox is not configured properly.\nFor X11, add following to the profile file.\nexport MOZ_USE_XINPUT2=1 For Wayland, same in the profile file.\nexport MOZ_ENABLE_WAYLAND=1 Framework laptop specific Framework laptop needs some additional tweaks.\nAmbient Light Sensor # pacman -S iio-sensor-proxy Fingerprint # pacman -S fprintd Bluetooth # pacman -S bluez bluez-utils # systemctl enable --now bluetooth Touchpad Two-finger/Three-finger Click Get touchpad device id # xinput Add to .xinitrc # xinput set-prop \u0026lt;device\u0026gt; \u0026#39;libinput Click Method Enabled\u0026#39; 0 1 Brightness Keys Add to kernel parameters:\n# Kernel parameters ... module_blacklist=hid_sensor_hub ... Suspend Power Add to kernel parameters:\n# Kernel parameters ... mem_sleep_default=deep nvme.noacpi=1 ... ","permalink":"https://peromage.github.io/p/arch-linux-on-laptop/","tags":["arch_linux","laptop"],"title":"Arch Linux on Laptop"},{"categories":["tech"],"contents":"Though I\u0026rsquo;ve written posts about dual-booting Windows and Linux and multi-booting a USB drive, I have to go back and dig useful information out each time when I forget something.\nAfter breaking my dual-boot setup once again (forgot to backup boot partition), I decided to create this post for a quick reference.\nThis reference assumes system is boot from UEFI and Windows is installed on a dedicated partition.\nSetup A USB With System Images Forget the previous multi-boot USB post. Use Ventory and it just works great.\nIn this case we need a Linux and Windows ISO. For Linux, I prefer Arch. For Windows, we need a PE environment. I don\u0026rsquo;t trust those PE ISOs from other people so the best way is to download an official image from Microsoft since we just need some tools and they are included in the installation ISO already.\nMethod 1: Load Windows From GRUB To prevent Windows from messing up with Linux\u0026rsquo;s bootloader, a good idea is to put Windows\u0026rsquo; bootloader in a VHD file and chainload it from GRUB.\nFix Windows\u0026rsquo;s Bootloader Boot into Windows installation ISO.\nDon\u0026rsquo;t start installing. Instead, choose Repair your computer -\u0026gt; Troubleshoot -\u0026gt; Command Prompt.\nWe need to create a VHD that contains Windows bootmgr. I used to create a file in 32 MB but it seems too small for the most recent bloated Windows so in case, we use 128 MB here.\nNOTE: This file will be loaded into memory so don\u0026rsquo;t make it too big.\nIn diskpart, use list volume to confirm EFI partition volume letter. Usually it will not be assigned by PE environment automatically.\nNOTE: The file can be put in Windows partition though. It requires extra setup like load NTFS module for grub and find it\u0026rsquo;s root. That\u0026rsquo;s too cumbersome.\n\u0026gt; diskpart DISKPART\u0026gt; list volume # EFI partition DISKPART\u0026gt; select volume 2 DISKPART\u0026gt; assign letter=e DISKPART\u0026gt; create vdisk file=e:\\bootmgr.vhd maximum=128 type=fixed DISKPART\u0026gt; select vdisk file=e:\\bootmgr.vhd DISKPART\u0026gt; attach vdisk DISKPART\u0026gt; convert mbr DISKPART\u0026gt; create partition primary DISKPART\u0026gt; format fs=ntfs quick DISKPART\u0026gt; assign letter=f DISKPART\u0026gt; exit Now the bootloader VHD is mounted at F:. Then write the boot record and create boot configuration files.\nNOTE: Windows partition volume letter should be confirmed in diskpart above. It\u0026rsquo;s usually assigned by PE automatically. In this case it is C:.\n\u0026gt; bootsect /nt60 e: /mbr \u0026gt; bcdboot c:\\Windows /l en-us /s e: /f uefi Add Window to GRUB Boot into Linux and confirm EFI partition UUID where you put the Windows bootloader VHD file. In command line:\n$ lsblk -f Configure GRUB menu to include Windows. Assume the EFI partition is mounted at /boot/efi and memdisk (got from syslinux) is put at EFI partition\u0026rsquo;s root.\n$ sudo cat \u0026lt;\u0026lt;EOF \u0026gt;\u0026gt;/etc/grub.d/40_custom menuentry \u0026#34;Windows 10\u0026#34; { search --set=root --no-floppy --fs-uuid 1DB1-9C31 linux16 /memdisk harddisk initrd16 /bootmgr.vhd } EOF $ sudo grub-mkconfig -o /boot/grub/grub.cfg Problem I found that on Fedora linux16 and initrd16 is not available by default. A workaround must be done. If it comes in this case, I suggest to use method 2 below.\nMethod 2: Add Windows Back To UEFI Menu This method is simpler and it takes advantage of UEFI boot menu but there is possibility that Windows is going to break Linux if Linux is the default.\nFix Windows\u0026rsquo;s Bootloader Boot into Windows installation ISO.\nDon\u0026rsquo;t start installing. Instead, choose Repair your computer -\u0026gt; Troubleshoot -\u0026gt; Command Prompt.\nIn diskpart, use list volume to confirm EFI partition volume letter. Usually it will not be assigned by PE environment automatically.\nFirst, mount EFI partition and backup Linux EFI files because Windows will overwrite the default settings :).\n\u0026gt; diskpart DISKPART\u0026gt; list volume # EFI partition DISKPART\u0026gt; select volume 2 DISKPART\u0026gt; assign letter=e DISKPART\u0026gt; exit # Backup default UEFI entry (Linux) \u0026gt; cd /d e:\\EFI \u0026gt; ren BOOT linux_BOOT Then Create Windows boot files.\n# Windows volume is C: confirmed from diskpart above \u0026gt; bcdboot c:\\Windows /l en-us /s e: /f uefi Lastly, restore Linux as the default start option. If you want Windows to be the default, leave it as it.\nNOTE: For Fedora it seems to be a problem to be a none-default entry when log into display manager. Not sure why. So it\u0026rsquo;d be better to restore default for Fedora.\n# Restore default Linux entry \u0026gt; ren Boot Microsoft_Boot \u0026gt; ren linux_BOOT BOOT ","permalink":"https://peromage.github.io/p/windows-rescure-quick-reference/","tags":["multi_boot","windows"],"title":"Windows Rescure Quick Reference"},{"categories":["linux"],"contents":"I found that every time when I try to setup VNC for remote access I always have troubles so this post serves as a note for myself.\nBe aware VNC only works for X (not sure about Wayland).\nChoose a VNC Server Generally I use TigerVNC. It\u0026rsquo;s a fork of TightVNC with good performance and easy configuration.\nIt has two types of installations:\nStandalone: It creates a new X server when the client is connected. Independent from the local X server. Scraping: It mirrors the local X server, like screen sharing. Usually they are shipped with individual packages. To install, for example, on Ubuntu\n$ sudo apt install tigervnc-standalone-server $ sudo apt install tigervnc-scraping-server Usually I would go with the scraping mode since open windows persist as long as the user is not logged out. And also I can quickly jump onto the physical desktop if it is needed. Unlike the standalone mode which closes all the windows when the service is stopped or restarted.\nStandalone Server Configuring a standalone server is fairly easy. You would only need three things: client password, server config and server startup script. They are all located under $HOME/.vnc/.\nCreate the password file. $ vncpasswd Create the server config file ($HOME/.vnc/config). A minimal configuration is shown as following. geometry=1366x768 alwaysshared localhost Create the server startup script ($HOME/.vnc/xstartup). This is also a minimal configuration. #!/bin/sh unset DBUS_SESSION_BUS_ADDRESS vncconfig -iconic \u0026amp; dbus-launch --exit-with-session /usr/bin/gnome-session --session=ubuntu Be aware that the last line dbus-launch is important on some distros that are shipped with default desktop environment. Without it the VNC server could not be started correctly. This is because the newly launched desktop environment tries to reuse the existing D-Bus but it\u0026rsquo;s occupied by the local X server already. dbus-launch makes sure it runs in its own little world. See dbus-launch\u0026rsquo;s man page for details.\nStart the server. Make sure the display port is not used by anyone else. $ vncserver :1 Connect from the client. On the remote PC: $ ssh -L 5901:localhost:5901 -t user@ip The TCP port depends on the display port used to start the VNC server. The equation is like: TCP_PORT = 5900 + DISPLAY_PORT. Usually the :0 is taken by local X server.\nUse any VNC client to connect to localhost:5901.\nAdd it as a Systemd service Add the service file.\n# $HOME/.config/systemd/user/vncserver.service [Service] ExecStart=vncserver :1 Restart=on-failure [Install] WantedBy=default.target Start the service.\nsystemctl --user enable vncserver.service systemctl --user start vncserver.service Scraping Server Configuring a scraping server is slightly different from the standalone server but it\u0026rsquo;s not hard.\nCreate the password file. Same with the standalone server. $ vncpasswd Start the server. This is where it\u0026rsquo;s different from the standalone one. Since it replicates the local X server it doesn\u0026rsquo;t need the configuration. $ x0vncserver -rfbauth $HOME/.vnc/passwd -display :0 Don\u0026rsquo;t forget to specify the password file or you\u0026rsquo;ll not be able to connect to it.\nConnect from the client. Same with the standalone server. On the remote PC: $ ssh -L 5900:localhost:5900 -t user@ip Local X server already uses display port :0. Then use any VNC client to connect to localhost:5900.\nAdd it as a Systemd service CAVEAT: The user must be configured to auto login, otherwise the user has to be logged in manually in order to start the service (make display :0 ready).\n# $HOME/.config/systemd/user/x0vncserver.service [Service] ExecStart=x0tigervncserver -display :0 -rfbauth %h/.vnc/passwd # Restart when :0 is not ready RestartForceExitStatus=1 # General restart #Restart=on-failure [Install] WantedBy=default.target Start the service.\nsystemctl --user enable x0vncserver.service systemctl --user start x0vncserver.service Synonyms of TigerVNC I was confused by the TigerVNC since there are similar commands. It turned out they are the same.\nvncserver -\u0026gt; tigervncserver vncconfig -\u0026gt; tigervncconfig vncpasswd -\u0026gt; tigervncpasswd x0vncserver -\u0026gt; tigerx0vncserver ","permalink":"https://peromage.github.io/p/vnc-quick-guide/","tags":["vnc","remote"],"title":"VNC Quick Guide"},{"categories":["coding"],"contents":"Troubles When working with a complicated project where you have to compare different history versions side by side, it soon becomes frustrating frequently checking out refs.\nThe old stupid way is to clone multiple repos and checkout to the specific revisions. When the project is big this might be a trouble because you\u0026rsquo;re basically duplicating files.\nSavior Git provides a convenience sub-command worktree to checkout a specific ref in another directory without duplicating files.\nAdd a New Checkout $ git worktree add ../foo-ref-1 \u0026lt;ref\u0026gt; Of course you can add as many checkouts as you want.\nRemove a Checkout When the checkout is no longer needed, it can be deleted from this command.\n$ git worktree remove --force ../foo-ref-1 If there are uncommitted changes git will prevent you from deleting the directory. In this case --force flag is needed.\n","permalink":"https://peromage.github.io/p/use-git-worktree-to-work-with-multiple-checkout-at-the-same-time/","tags":["git"],"title":"Use Git Worktree to Work with Multiple Checkout at the Same Time"},{"categories":["emacs"],"contents":"Autoloading is a neat feature in Emacs. It speeds up Emacs by lazy load the files. But it could be a little confusing if you\u0026rsquo;re switching from Vim.\nMyth - Not Working as Expected If you have used Vim you know in Vim you can put your library files to the load path variable and Vim autoloads them whenever one of the functions/variables is used. Initially I thought this is the same in Emacs but with a little effort to put the magic autoload comments before the function/variable definition. It turned out I was wrong. When I called my functions Emacs could not find them until I explicitly require them. This is obviously not my intention.\nMake It Work After carefully reading the document, I got that the magic autoload comment is just a autoload cookie that guides Emacs to generate the real autoload code. In one word, I have to define the function/variable autoload definition anyways. But with the cookies it simplifies the process.\nAdd magic comment ;;;###autoload before the desired function/variable definition. M-x update-file-autoloads command on the library file which contains the definitions that need to be autoloaded. Store that generated autoload definition file with a different name. Require that autoload definition file in the init.el. That\u0026rsquo;s the process to autoload the custom library. The downside is the update-file-autoloads command has to be called every time the library file is updated.\nAlternative way is to use package-install-from-buffer to install the library file as a package. package.el does the dirty work for you, takes care of autoload definition generation and loading automatically.\nReference https://emacs.stackexchange.com/questions/8023/how-to-use-autoload ","permalink":"https://peromage.github.io/p/autoloading-in-emacs/","tags":["emacs","autoloading"],"title":"Autoloading in Emacs"},{"categories":["emacs"],"contents":"I\u0026rsquo;ve been using Emacs since last year but until recent I started using org-mode seriously. After spending a couple of days reading and watching all kinds of org tutorial as well as using it for documentation, I realized that people who invented this must geniuses.\nOrg document seems similar with Markdown: they are text markup format. However, Org provides far more capabilities to store metadata and greater editing experience together with Emacs\u0026rsquo; org-mode.\nMotivation I used to use Markdown to write my blog articles and use Hugo to generate static files.\nThe workflow is pretty much like:\nCreate a new Markdown with header by either snippet template from text editor or Hugo command. Write the article. Set last modified time upon finished. Commit and push then let GitHub CI to generate static files automatically. It looks typical but later on I found it was really frustrating to manage my articles:\nI always forgot to update the last modified time. Tags and categories were set in the header each file. It\u0026rsquo;s difficult check existing tags and categories and make them consistent in the new articles. For example, I always forgot whether a tag or category was capitalized or dash separated. Painful to browse. Because of those troubles I gradually lost interests writing articles until I found org-mode. So I started planning to manage my articles with it.\nChoose the Right Way By checking Hugo\u0026rsquo;s documents, I found that it supports Org backend with go-org. However it seems like just another Markdown method but in Org syntax. Apparently it doesn\u0026rsquo;t use the full Org capabilities.\nLater I found ox-hugo which is an Org backend in Emacs used for Org file export. The idea is to write articles in Org syntax with metadata and whatever you like to do in org-mode and then export to Markdown files through ox-hugo. Finally feed the Markdown files to the Hugo engine. The killer feature is that it supports exporting from subtrees, which means you can manage all my articles in one file categorize them with ease (by the first level outline). And since all the articles are in the same visible file, they can be refiled and move around with org-mode key bindings. Also all tags are visible and can be applied very easily. It gives you a lot flexibility to manage the articles in this way.\nAt the time when this article is read, it\u0026rsquo;s been written in org-mode already. I even use the same file to manage other pages of my blog like about, archives and search pages. You can checkout my original Org file here to figure out how they are defined.\nUpdate CI to Build Static Files on Pushing Since all the articles are managed by the Org file there is no point to keep the old Markdown files. I need to make GitHub CI export the Org file for me so I don\u0026rsquo;t have to do it locally.\nThe problem is to setup Emacs on the job runner. Luckily there are people doing this already by providing a GitHub action. Thanks Steve Purcell and the people who worked on this!\nNow with the Emacs setup ready, one problem left is to export from Org files to Markdown. The idea is pretty straight forward: install ox-hugo from MELPA and export through it. A simple shell command should do the job.\nemacs -nw --batch --eval \\ \u0026#39;(progn (package-initialize) (add-to-list (quote package-archives) (quote (\u0026#34;melpa\u0026#34; . \u0026#34;https://melpa.org/packages/\u0026#34;))) (package-refresh-contents) (package-install (quote ox-hugo)) (find-file \u0026#34;myblog/blog.org\u0026#34;) (org-hugo-export-wim-to-md :all))\u0026#39; After that, feed the generated Markdown files to Hugo engine. No difference from the typical Hugo workflow.\nSee here for my job runner script and workflow configuration.\nFix the Last Modified Date By doing this workflow all the files are always generated so their last modified date are constantly changed (with #+hugo_auto_set_lastmod: t in the header). ox-hugo seems not to have a proper solution to calculate the diff between changes (could be hard though). The best way to solve this is to add either a :LOGBOOK: or a EXPORT_HUGO_LASTMOD property to the subtree. Or even simpler to use TODO and DONE workflow since it generates :LOGBOOK: automatically. When any one of them specified ox-hugo will the value from it instead of generating a new date.\nSince manually changing the modification time in EXPORT_HUGO_LASTMOD sucks and it\u0026rsquo;s the same solution back in the Markdown style, this time I decided to use \u0026ldquo;Org\u0026rdquo; way to fix this problem. By looking at the document, :LOGBOOK: has the highest priority among other options and also has a synergy with todo workflow. That\u0026rsquo;s cool. I can treat my article writing like any other tasks.\nBut I don\u0026rsquo;t quite like the default keywords TODO and DONE since they doesn\u0026rsquo;t sound semantic to the articles. So I added a header to my blog Org file: #+seq_todo: DRAFT(d) | PUBLISHED(p!).\nThen I found another problem that whenever I change the state from DRAFT to PUBLISHED there is always a CLOSED time property added to the article. This is because I have (setq org-log-done 'time) in my Emacs configuration file. It duplicates :LOGBOOK: since it has already logged the transition time and I don\u0026rsquo;t want to change my Emacs configuration specific for this file. So I added another header to my blog Org file: #+startup: nologdone and also make sure the state transition records are always put into the drawer: #+startup: logdrawer.\nOkay now I should be able to start a new article with DRAFT prefix and then use C-c C-t to change it to PUBLISHED whenever I\u0026rsquo;m done writing. However things are still not going as I expected. Remember the date precedence page? The first transition to PUBLISHED state record is recognized as the creation date. Only the second or later records to PUBLISHED state will be read as the last modified date. That\u0026rsquo;s dumb. To fix this, I added a new todo item and now it\u0026rsquo;s like: #+seq_todo: DRAFT(d) | CREATED(c!) PUBLISHED(p!).\nNow my blog header is like:\n#+author: Fang Deng #+startup: show2levels #+startup: nologdone #+startup: logdrawer #+seq_todo: DRAFT(d) | CREATED(c!) PUBLISHED(p!) #+options: d:t #+hugo_base_dir: ../ #+hugo_section: blog #+hugo_auto_set_lastmod: t Don\u0026rsquo;t forget the #+options: d:t. ox-hugo will not export :LOGBOOK: without it.\nFinally a sweet snippet file to save my life.\n# -*- mode: snippet -*- # name: Hugo new article # key: hugonew # -- ** DRAFT ${1:TITLE} :PROPERTIES: :EXPORT_FILE_NAME: ${1:$(replace-regexp-in-string \u0026#34;[^A-Za-z0-9._-]\u0026#34; \u0026#34;\u0026#34; (replace-regexp-in-string \u0026#34; \u0026#34; \u0026#34;-\u0026#34; (downcase yas-text)))} :END: :LOGBOOK: - State \u0026#34;CREATED\u0026#34; from [`(string-trim (format-time-string (cdr org-time-stamp-formats)) \u0026#34;\u0026lt;\u0026#34; \u0026#34;\u0026gt;\u0026#34;)`] :END: $0 Now a new article will come with its creation time. Whenever the article is done, C-c C-t to mark it PUBLISHED which will be the last modified time. If the article is modified in the future, simply C-c C-t again to add another PUBLISHED state and the last modified time will be refreshed on export. Now I have a neat log book to record my changes. No more manually editing suckers!\n","permalink":"https://peromage.github.io/p/use-org-mode-to-manage-my-blog/","tags":["emacs","org","markdown","hugo","ox_hugo"],"title":"Use Org Mode to Manage My Blog"},{"categories":null,"contents":"Attributes C++ developer Emacser Open source advocate Likes Lisp and functional programming Has a lot hair :) About I\u0026rsquo;m a C++ software developer working for an automotive company. I like C++ and use it extensively at work. However, I also use other popular languages like C#, Python, Java, JavaScript(TypeScript) and Rust from time to time.\nWriting blog is one of my hobbies and mainly for personal noting purposes so some content might be trivial.\nYou can find my contact at the bottom of this page.\n","permalink":"https://peromage.github.io/about/","tags":null,"title":"Fang Deng"},{"categories":null,"contents":"","permalink":"https://peromage.github.io/search/","tags":null,"title":"Search"},{"categories":["coding"],"contents":"Background I\u0026rsquo;ve been working on optimization for some C++ code recently. One of the part is to initialize some data at compile time. Consider we have a C style enum definition:\ntypedef enum Foo { AAA = 0, BBB, CCC } Foo_t; We want to have an array of the enum with undefined initial values 999 because by default initialization the values would be 0\u0026rsquo;s. However, std::array can only be initialized by initializer list, which is said:\n// Partial initialization constexpr std::array\u0026lt;Foo_t, 5\u0026gt; array {static_cast\u0026lt;Foo_t\u0026gt;(999), static_cast\u0026lt;Foo_t\u0026gt;(999)}; // Results in int equivalent: {999, 999, 0, 0, 0} If there are a hundred of elements then you have to write all of them down in the list.\nYou can, of course, initialize it in a loop but this sacrifices runtime performance.\n// Runtime initialization std::array\u0026lt;Foo_t, 5\u0026gt; array {}; for (auto\u0026amp; i : array) { i = static_cast\u0026lt;Foo_t\u0026gt;(999); } // Results in int equivalent: {999, 999, 999, 999, 999} Generating code by templates We can use recursive deduction of templates to generate our code. There is a limit that you can only do 1024 times of recursion but in my case it\u0026rsquo;s enough.\nThe idea is to count the size to zero and use variadic argument to increase the number of arguments on each recursion. Finally the size of the array will be passed to the bottom and the variadic argument gets expanded.\nIt\u0026rsquo;s a pretty simple trick.\ntemplate\u0026lt;std::size_t N, std::size_t M, typename T, typename... U\u0026gt; struct ARR_IMPL { static constexpr auto arr = ARR_IMPL\u0026lt;N, M-1, T, T, U...\u0026gt;::arr; }; template\u0026lt;std::size_t N, typename T, typename... U\u0026gt; struct ARR_IMPL\u0026lt;N, 0, T, U...\u0026gt; { static constexpr std::array\u0026lt;T, N\u0026gt; arr {static_cast\u0026lt;U\u0026gt;(999)...}; }; template\u0026lt;std::size_t N, typename T\u0026gt; struct ARR { static constexpr auto arr = ARR_IMPL\u0026lt;N, N-1, T, T\u0026gt;::arr; }; constexpr auto array1 = ARR\u0026lt;5, Foo_t\u0026gt;::arr; constexpr auto array2 = ARR\u0026lt;100, Foo_t\u0026gt;::arr; // array1 results in int equivalent: {999, 999, 999, 999, 999} // array2 results in int equivalent: {999, 999, 999, 999, 999, ...} ","permalink":"https://peromage.github.io/p/initialize-stdarray-at-compile-time/","tags":["cpp","meta_programming"],"title":"Initialize std::array at Compile Time"},{"categories":["linux"],"contents":"Before Starting This post mainly discusses VM setup for Windows since I\u0026rsquo;ve been using Windows as a secondary OS for apps or games that cannot run on Linux.\nThis post discusses setup on Arch Linux.\nThis post assumes the CPU and motherboard support VT-d and IOMMU features. Detailed prerequisites can be found on this page.\nInstall Hypervisor Follow Arch wiki to install and setup:\nQEMU Libvirt Virt-Manager OVMF Install Windows VM Before Installation Download the latest Windows 10 ISO from Microsoft. Windows 11 is buggy and requires Microsoft account login during installation, which sucks.\nWe also need to get VirtIO driver before installing Windows.\nDuring Installation Then create a new VM with the following configuration before starting installation:\nOverview: Change Firmware to UEFI. CPUs: Unselect Copy host CPU configuration and change Model to host-passthrough. Select Manually set CPU topology. Change Sockets to 1, Cores to 4, Threads to 2 (Physical core 4 * threads for each core 2). Disk: Change Disk bus to VirtIO. NIC: Change Device model to VirtIO. Display Spice: Use Type Spice server. Video: Use Model QXL. During the installation, the Windows installer may not be able to find the disk because it doesn\u0026rsquo;t have the driver (that\u0026rsquo;s why you have to download it beforehand). Load the driver from the ISO and continue installation. This step should be trivial.\nOptional: Use VHD(X) Native Boot QCOW and raw format image files have decent performance. However, in most cases the guest Windows prefers to be installed on a real SSD drive to achieve maximum I/O. But you have experience installing Windows you would know that Windows creates several unnecessary partitions during installation. I don\u0026rsquo;t want Windows to occupy the whole disk and create those clusters, especially on a portable SSD drive. I probably use the disk for other purposes and having those partitions is a really bad idea. It also looks ugly.\nThis VHD(X) native boot trick I have used it in dual-booting Windows and Linux before.\nTo start, passthrough the SSD drive with SATA bus (don\u0026rsquo;t use VirtIO for now). Then boot into Windows installation ISO and press Shift+F10 to open a CMD window (Yes, you don\u0026rsquo;t even need to start the installation process).\nFirst we need to create the partitions. In the CMD window:\n\u0026gt; diskpart # List all disks DISKPART\u0026gt; list disk # Choose the SSD drive DISKPART\u0026gt; select disk 0 # Make sure have a backup as this wipes out the whole disk DISKPART\u0026gt; clean # Creat the partition table DISKPART\u0026gt; convert gpt # An EFI partition is necessary DISKPART\u0026gt; create partition efi size=512 DISKPART\u0026gt; select partition 1 DISKPART\u0026gt; format fs=fat quick DISKPART\u0026gt; assign letter=E # Assign the rest space for our main partition DISKPART\u0026gt; create partition primary DISKPART\u0026gt; select partition 2 DISKPART\u0026gt; format fs=ntfs quick DISKPART\u0026gt; assign letter=D # Create a VHD file to host the Windows system files # Note: Better use VHDX format as it has data corruption protection DISKPART\u0026gt; create vdisk file=f:\\win.vhdx maximum=64000 type=fixed DISKPART\u0026gt; select vdisk file=f:\\win.vhdx DISKPART\u0026gt; attach vdisk DISKPART\u0026gt; convert gpt DISKPART\u0026gt; create partition primary DISKPART\u0026gt; format fs=ntfs quick DISKPART\u0026gt; assign letter=H DISKPART\u0026gt; exit Now we have EFI partition assigned to E:, data partition assigned to D: and Windows VHD mounted at H:.\nThen extract Windows files to H:, but before that we need to make sure select the correct version that we want to install.\nAssume the installation medium is mounted at G:.\n\u0026gt; dism /get-wiminfo /wimfile=g:\\sources\\install.wim There would be a list of different versions that this installation medium has. For me, Windows 10 Pro for Workstations is at 10. Then I can use the following command to extract it to H:.\n\u0026gt; dism /apply-image /imagefile:g:\\sources\\install.wim /index:10 /applydir:h:\\ Lastly, fix the bootloader. Make sure install the bootloader files to the EFI partition.\n\u0026gt; bcdboot h:\\Windows /l en-us /s e: /f uefi Reboot and finish Windows installation. Don\u0026rsquo;t forget to switch the SSD bus to VirtIO after installing the driver.\nAfter Installation Keep the VirtIO ISO in the CD ROM device when boot into Windows. Find virtio-win-gt-x64.msi and virtio-win-guest-tools.exe then install them both. Then power off VM.\nThen configure VM:\nAdd Hardware -\u0026gt; Channel -\u0026gt; Select org.qemu.guest_agent.0 -\u0026gt; Finish Until here, the basic Windows VM setup is done.\nNote The video device doesn\u0026rsquo;t support VirtIO on Windows so we have to use QXL for now.\nPassthrough: Discrete Graphic Card Identify Discrete Graphic Card In a terminal:\n$ lspci -nnk | grep -A 3 -i nvidia 01:00.0 VGA compatible controller [0300]: NVIDIA Corporation GM204 [GeForce GTX 970] [10de:13c2] (rev a1) Subsystem: Gigabyte Technology Co., Ltd Device [1458:367a] Kernel driver in use: nouveau Kernel modules: nouveau 01:00.1 Audio device [0403]: NVIDIA Corporation GM204 High Definition Audio Controller [10de:0fbb] (rev a1) Subsystem: Gigabyte Technology Co., Ltd Device [1458:367a] Kernel driver in use: snd_hda_intel Kernel modules: snd_hda_intel Take a note of the device IDs. In this example I have a Nvidia GTX970 graphic card along with a audio controller. They belong to the same group (domain) you have to take them all.\nIn this case I got 10de:13c2 and 10de:0fbb. These are the PCI devices that will be passed through to the VM. Other PCI devices can be passed too.\nAdd Kernel Modules Add following modules to mkinitcpio.conf.\n# /etc/mkinitcpio.conf MODULES=(vfio_pci vfio vfio_iommu_type1 vfio_virqfd) Then regenerate ramfs.\n$ sudo mkinitcpio -P Add Kernel Parameters Then we\u0026rsquo;re going to enable IOMMU and prevent host Linux loading PCI devices that we want to passthrough to the VM.\nThe kernel parameter passing could be different depending on the bootloader you use. In this example, I use systemd-boot.\nEdit the system entry. Add intel_iommu=on to the kernel parameter along with vfio-pci.ids=10de:13c2,10de:0fbb which contains the device IDs we got from the previous step.\n# /boot/loader/entries/arch.conf options intel_iommu=on vfio-pci.ids=10de:13c2,10de:0fbb After reboot, verify IOMMU is enabled successfully via dmesg.\n$ sudo dmesg | grep -i -e DMAR -e IOMMU [ 0.000000] ACPI: DMAR 0x00000000BDCB1CB0 0000B8 (v01 INTEL BDW 00000001 INTL 00000001) [ 0.000000] Intel-IOMMU: enabled [ 0.028879] dmar: IOMMU 0: reg_base_addr fed90000 ver 1:0 cap c0000020660462 ecap f0101a [ 0.028883] dmar: IOMMU 1: reg_base_addr fed91000 ver 1:0 cap d2008c20660462 ecap f010da [ 0.028950] IOAPIC id 8 under DRHD base 0xfed91000 IOMMU 1 [ 0.536212] DMAR: No ATSR found [ 0.536229] IOMMU 0 0xfed90000: using Queued invalidation [ 0.536230] IOMMU 1 0xfed91000: using Queued invalidation [ 0.536231] IOMMU: Setting RMRR: [ 0.536241] IOMMU: Setting identity map for device 0000:00:02.0 [0xbf000000 - 0xcf1fffff] [ 0.537490] IOMMU: Setting identity map for device 0000:00:14.0 [0xbdea8000 - 0xbdeb6fff] [ 0.537512] IOMMU: Setting identity map for device 0000:00:1a.0 [0xbdea8000 - 0xbdeb6fff] [ 0.537530] IOMMU: Setting identity map for device 0000:00:1d.0 [0xbdea8000 - 0xbdeb6fff] [ 0.537543] IOMMU: Prepare 0-16MiB unity mapping for LPC [ 0.537549] IOMMU: Setting identity map for device 0000:00:1f.0 [0x0 - 0xffffff] [ 2.182790] [drm] DMAR active, disabling use of stolen memory Also, make sure VFIO driver is loaded.\n$ lspci -nnk | grep -i -A 3 nvidia 04:00.0 VGA compatible controller [0300]: NVIDIA Corporation GM204 [GeForce GTX 970] [10de:13c2] (rev a1) Subsystem: Gigabyte Technology Co., Ltd Device [1458:367a] Kernel driver in use: vfio-pci Kernel modules: nouveau 04:00.1 Audio device [0403]: NVIDIA Corporation GM204 High Definition Audio Controller [10de:0fbb] (rev a1) Subsystem: Gigabyte Technology Co., Ltd Device [1458:367a] Kernel driver in use: vfio-pci Kernel modules: snd_hda_intel Passthrough PCI Open VM settings and add the discrete graphic card as well as it\u0026rsquo;s audio controller etc.\nInstall Drivers Boot into Windows VM, now you should be able to install the graphic card driver.\nFix Error Code 43 The latest Windows 10/11 should not have this problem. However, in any case if display adapter is malfunctioning and showing error code 43, use following workaround to avoid it.\nThen open VM settings in XML view, add following content in the relevant sections to prevent Nvidia driver installer discovering the VM environment. Some sections may exist already so just append to them.\n\u0026lt;domain\u0026gt; \u0026lt;features\u0026gt; \u0026lt;hyperv\u0026gt; \u0026lt;vendor_id state=\u0026#39;on\u0026#39; value=\u0026#39;1234567890ab\u0026#39;/\u0026gt; \u0026lt;/hyperv\u0026gt; \u0026lt;kvm\u0026gt; \u0026lt;hidden state=\u0026#39;on\u0026#39;\u0026gt; \u0026lt;/kvm\u0026gt; \u0026lt;/features\u0026gt; \u0026lt;/domain\u0026gt; Passthrough Enclosure Device I\u0026rsquo;m using Razer Core Chroma and Synapse is not available on Linux. In order to adjust RGB lights, pass the enclosure from USB device list.\nNotes My setup is based on external GPU. If eGPU is powered on when laptop starts, somehow the kernel will be stuck. The eGPU has to be powered off and then powered on when system is up. Weird.\nPassthrough: Integrated Graphic Card with SR-IOV I have a fairly new laptop with 12th gen Intel and Iris Xe graphic card but no discrete one. In this case Intel has provided a technology call SR-IOV which allows me to passthrough a part of my iGPU to the VM.\nNote: GVT-g is only supported on 5th gen to 10th gen Intel CPUs.\nInstall Kernel Module I was following this GitHub issue. Basically an Intel customized i915 kernel module is needed. However, thanks to @strongtz who has created an AUR package so the Intel custom kernel is not required. All we need is this AUR package, which is awesome.\nAfter installing the AUR package, update kernel parameters to enable IOMMU and SR-IOV virtual functions.\n# /boot/loader/entries/arch.conf options intel_iommu=on iommu=pt i915.enable_guc=7 Also add it to mkinitcpio.conf\n# /etc/mkinitcpio.conf MODULES=(i915) Then reboot the system.\nCreate Virtual Functions If hardware supports and configuration is correct, the following kernel message should be observed.\n$ sudo dmesg | grep i915_virtualization_probe [ 1.740640] i915 0000:00:02.0: i915_virtualization_probe: entry Then identify the iGPU by lspci. Usually Intel device starts with 00:02.x.\n$ lspci | grep -P \u0026#34;VGA.*Intel\u0026#34; 00:02.0 VGA compatible controller: Intel Corporation Alder Lake-P Integrated Graphics Controller (rev 0c) Then we should be able to get the number of virtual functions allowed currently.\n$ cat /sys/devices/pci0000:00/0000:00:02.0/sriov_numvfs 0 To enable virtual functions, run this command as root user. I\u0026rsquo;m creating one virtual function since I only have one VM that needs it. Maximal 7 virtual functions can be created.\n$ su # echo 1 \u0026gt; /sys/devices/pci0000:00/0000:00:02.0/sriov_numvfs Finally check VGA device again, there should be an additional device created (the one starts with 00:02.1).\n$ lspci | grep -P \u0026#34;VGA.*Intel\u0026#34; 00:02.0 VGA compatible controller: Intel Corporation Alder Lake-P Integrated Graphics Controller (rev 0c) 00:02.1 VGA compatible controller: Intel Corporation Alder Lake-P Integrated Graphics Controller (rev 0c) Install Intel Graphics Driver Add the virtual PCI graphics adapter to VM (choose the shared on 00:02.1) and boot up Windows. Be aware that we still the QXL video adapter this time.\nWindows should now recognize a Display adapters/Microsoft Basic Display Adapter in Device Manager if everything is correct. Go to Intel website to get the latest driver.\nInstall it and reboot Windows. That adapter should now be recognized as Intel(R) Iris(R) Xe Graphics.\nInstall Looking Glass Since I\u0026rsquo;m setting this up on a laptop I don\u0026rsquo;t have external display so Looking Glass must be used to redirect the VM display on the laptop screen.\nCreate Shared Memory When the Windows VM is powered off, add the following content to the VM XML config (be aware of the hierarchy).\n\u0026lt;domain\u0026gt; \u0026lt;device\u0026gt; \u0026lt;shmem name=\u0026#39;looking-glass\u0026#39;\u0026gt; \u0026lt;model type=\u0026#39;ivshmem-plain\u0026#39;/\u0026gt; \u0026lt;size unit=\u0026#39;M\u0026#39;\u0026gt;64\u0026lt;/size\u0026gt; \u0026lt;/shmem\u0026gt; \u0026lt;/device\u0026gt; \u0026lt;/domain\u0026gt; The size of shared memory depends on the maximal resolution that Windows VM will be using. Simply this formula can be used. The result must be rounded up to the nearest power of 2.\ntotal bytes = width x height x 4 x 2 / 1024 / 1024 + 10 For example my Windows VM can setup maximal 2560x1600 so it would be 2560 x 1600 x 4 x 2 / 1024 / 1024 + 10 = 41.25. Then round it up to 64.\nAfter that, create a temp file config. The user name must match the user that is being used.\n# /etc/tmpfiles.d/10-looking-glass.conf #Type Path Mode UID GID Age Argument f /dev/shm/looking-glass 0660 user kvm - Create the temp file for the first time (it will be created automatically after reboot).\n$ sudo systemd-tmpfiles --create /etc/tmpfiles.d/10-looking-glass.conf Install Host Service Download and install Looking Glass service installer in Windows. Note that Windows is the host in Looking Glass\u0026rsquo;s context (Linux is the client that reads output from Windows VM).\nAdditionally, IVSHMEM driver is also needed so that Looking Glass service can shared the display via shared memory. It can be downloaded from RedHat.\nThen go to Device Manager and find System Devices/PCI standard RAM Controller. Update its driver with the downloaded IVSHMEM driver.\nSolve Display Adapter Error Code 43 Similarly I got the same error code as the passthrough for discrete graphic card. To solve it, add the following content to the VM config XML.\n\u0026lt;domain\u0026gt; \u0026lt;features\u0026gt; \u0026lt;hyperv\u0026gt; \u0026lt;vendor_id state=\u0026#39;on\u0026#39; value=\u0026#39;1234567890ab\u0026#39;/\u0026gt; \u0026lt;/hyperv\u0026gt; \u0026lt;kvm\u0026gt; \u0026lt;hidden state=\u0026#39;on\u0026#39;\u0026gt; \u0026lt;/kvm\u0026gt; \u0026lt;/features\u0026gt; \u0026lt;/domain\u0026gt; Create a Dummy Display Looking Glass mirrors display output so a display monitor must be connected to the eGPU\u0026rsquo;s output. If you don\u0026rsquo;t have a dummy HDMI dongle, a fake display device can be installed.\nDownload the IddSampleDriver from it\u0026rsquo;s release page.\nExtract all content to C:\\IddSampleDriver (Important since the path of config file is hard-coded). Run C:\\installCert.bat with Administrator privilege. Install display driver: Device Manager -\u0026gt; Add legacy haradware -\u0026gt; Advanced install -\u0026gt; Display adapter -\u0026gt; Browse driver on the disk -\u0026gt; Choose the inf file in the extracted directory. Restart Windows. Finish up Now get the same version of Looking Glass client (important). Compile and run. The VM should be running smoothly with graphic acceleration.\nPinned CPU Cores To reduce latency, I prefer manually allocating CPU cores for both host and guest. One thing needs to mention is this doesn\u0026rsquo;t prevent host process from running on the pinned cores. If the cores are expected to be used by VM only, consider isolate pinned cores.\nNote: I\u0026rsquo;ve noticed some sudden freeze if CPU cores are pinned while having some loads on Linux host side. Removing pinning and letting hypervisor decide itself seems to work fine, and the performance wise does not have too much difference. I don\u0026rsquo;t usually pin cores now unless it\u0026rsquo;s necessary.\nFirst find out how many cores the CPU has.\n$ lscpu -e CPU NODE SOCKET CORE L1d:L1i:L2:L3 ONLINE MAXMHZ MINMHZ MHZ 0 0 0 0 0:0:0:0 yes 4400.0000 400.0000 594.1430 1 0 0 0 0:0:0:0 yes 4400.0000 400.0000 987.0030 2 0 0 1 4:4:1:0 yes 4400.0000 400.0000 1144.1160 3 0 0 1 4:4:1:0 yes 4400.0000 400.0000 2100.0000 4 0 0 2 8:8:2:0 yes 4400.0000 400.0000 944.5790 5 0 0 2 8:8:2:0 yes 4400.0000 400.0000 975.3940 6 0 0 3 12:12:3:0 yes 4400.0000 400.0000 1116.9910 7 0 0 3 12:12:3:0 yes 4400.0000 400.0000 829.3560 8 0 0 4 16:16:4:0 yes 3300.0000 400.0000 1250.2290 9 0 0 5 17:17:4:0 yes 3300.0000 400.0000 1150.0020 10 0 0 6 18:18:4:0 yes 3300.0000 400.0000 1208.8120 11 0 0 7 19:19:4:0 yes 3300.0000 400.0000 1016.9800 12 0 0 8 20:20:5:0 yes 3300.0000 400.0000 1226.8660 13 0 0 9 21:21:5:0 yes 3300.0000 400.0000 1046.9780 14 0 0 10 22:22:5:0 yes 3300.0000 400.0000 1068.5780 15 0 0 11 23:23:5:0 yes 3300.0000 400.0000 2100.0000 My CPU is Intel 1240P. It has 4 performance cores and 8 efficiency cores. In my setup, I keep core 0 for host and pass the rest 3 performance cores and 2 efficiency cores to the guest (for 8 threads).\nAdd this configuration to the VM.\n\u0026lt;vcpu placement=\u0026#34;static\u0026#34;\u0026gt;8\u0026lt;/vcpu\u0026gt; \u0026lt;iothreads\u0026gt;1\u0026lt;/iothreads\u0026gt; \u0026lt;cputune\u0026gt; \u0026lt;vcpupin vcpu=\u0026#34;0\u0026#34; cpuset=\u0026#34;2\u0026#34;/\u0026gt; \u0026lt;vcpupin vcpu=\u0026#34;1\u0026#34; cpuset=\u0026#34;3\u0026#34;/\u0026gt; \u0026lt;vcpupin vcpu=\u0026#34;2\u0026#34; cpuset=\u0026#34;4\u0026#34;/\u0026gt; \u0026lt;vcpupin vcpu=\u0026#34;3\u0026#34; cpuset=\u0026#34;5\u0026#34;/\u0026gt; \u0026lt;vcpupin vcpu=\u0026#34;4\u0026#34; cpuset=\u0026#34;6\u0026#34;/\u0026gt; \u0026lt;vcpupin vcpu=\u0026#34;5\u0026#34; cpuset=\u0026#34;7\u0026#34;/\u0026gt; \u0026lt;vcpupin vcpu=\u0026#34;6\u0026#34; cpuset=\u0026#34;8\u0026#34;/\u0026gt; \u0026lt;vcpupin vcpu=\u0026#34;7\u0026#34; cpuset=\u0026#34;9\u0026#34;/\u0026gt; \u0026lt;emulatorpin cpuset=\u0026#34;0-1\u0026#34;/\u0026gt; \u0026lt;iothreadpin iothread=\u0026#34;1\u0026#34; cpuset=\u0026#34;0-1\u0026#34;/\u0026gt; \u0026lt;/cputune\u0026gt; \u0026lt;cpu mode=\u0026#34;host-passthrough\u0026#34; check=\u0026#34;none\u0026#34; migratable=\u0026#34;on\u0026#34;\u0026gt; \u0026lt;topology sockets=\u0026#34;1\u0026#34; dies=\u0026#34;1\u0026#34; cores=\u0026#34;4\u0026#34; threads=\u0026#34;2\u0026#34;/\u0026gt; \u0026lt;/cpu\u0026gt; Enable MSI(Message Signaled-Based Interrupts) Most likely by default the Windows VM will use Line-Base Interrupts which usually causes audio distortion and slow down the performance. In this case, we need to enable MSI.\nTo check what type of interrupts the graphic card is using at the moment, run this command as root while VM is running. 04:00 is my graphic card bus ID.\n$ sudo lspci -vs 04:00 | grep \u0026#39;MSI:\u0026#39; Capabilities: [68] MSI: Enable+ Count=1/1 Maskable- 64bit+ Capabilities: [68] MSI: Enable+ Count=1/1 Maskable- 64bit+ A - after Enable means MSI is supported, but not used by the virtual machine, while a + says that the virtual machine is using it. Since I have enabled it already the result shows + which is expected.\nThen go back to the Windows VM and enable MSI.\nIn Device Manager, find the graphic card: View -\u0026gt; Resource by type -\u0026gt; Interrupt request (IRQ) -\u0026gt; (PCI) 0xFFFFFFD0 (-48) NVIDIA GeForce GTX 970.\nThe value in the parenthesis also reflects the interrupt status. Positive value means Line-Based Interrupt mode and negative value means Message Signaled-Based mode. As my card has already been tweaked, it is negative value here.\nTo enable MSI: open the property of (PCI) 0xFFFFFFD0 (-48) NVIDIA GeForce GTX 970 -\u0026gt; Details -\u0026gt; in the Property dropdown menu select Device instance path.\nNote down the value of this property. In my case it is PCI\\VEN_10DE\u0026amp;DEV_13C2\u0026amp;SUBSYS_367A1458\u0026amp;REV_A1\\4\u0026amp;123CFF10\u0026amp;0\u0026amp;000C.\nThen open Registry Editor and find out the device entry. It should be a subkey of Computer\\HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Enum. E.g. PCI\\VEN_10DE\u0026amp;DEV_13C2\u0026amp;SUBSYS_367A1458\u0026amp;REV_A1\\4\u0026amp;123cff10\u0026amp;0\u0026amp;000C\\Device Parameters\\Interrupt Management. From there, create a new key named MessageSignaledInterruptProperties as well as a DWORD value MSISupported with data 1 (Change the data if it exists already).\nIn addition to the graphic card itself, the audio device on the card also needs to be tweaked. Audio device should have the same vendor ID and a different device ID which can be obtained from the previous section. Normally it should be adjacent to the card. For example Computer\\HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Enum\\PCI\\VEN_10DE\u0026amp;DEV_0FBB\u0026amp;SUBSYS_367A1458\u0026amp;REV_A1\\4\u0026amp;336a283\u0026amp;0\u0026amp;0010\\Device Parameters\\Interrupt Management\\MessageSignaledInterruptProperties. Similarly update the data to 1.\nNow reboot Windows and check if graphic card works from Device Manager as well as the IRQ value which shows MSI status.\nHuge Memory Pages Normally, I don\u0026rsquo;t think I really need this setup. In any case if it\u0026rsquo;s needed, I\u0026rsquo;ll use static huge pages. With static huge pages, a portion of memory will be allocated for VM and can\u0026rsquo;t be used by host.\nTo verify is CPU supports it.\n$ grep pdpe1gb /proc/cpuinfo Add kernel parameters.\n# /boot/loader/entries/arch.conf options default_hugepagesz=1G hugepagesz=1G hugepages=X Add this configuration to the VM.\n\u0026lt;memoryBacking\u0026gt; \u0026lt;hugepages/\u0026gt; \u0026lt;/memoryBacking\u0026gt; Audio Redirection By default the audio is output from HDMI through the graphic card (if it supports). In order to use the laptop speaker, we need to install a special virtual audio device called scream.\nOn Arch, installing from AUR is the most convenient way. Then start the service by receiving audio through network. In this case, virbr0 is my NAT adapter.\n$ scream -i virbr0 On Windows, download and install the driver then switch output device to scream. It should work perfectly out of the box.\nAlternative Way to Stream Audio scream also supports stream through shared memory but it requires additional setup. Checkout it\u0026rsquo;s readme as it shows how to set it up. Usually, I don\u0026rsquo;t feel like I really need it. If there is obvious latency, this should a backup plan.\nReferences ArchWiki QEMU ArchWiki OVMF Intel GVT-g Looking Glass Virtio driver SR-IOV: mainlining? strongtz/i915-sriov-dkms ge9/IddSampleDriver GPU Passthrough + Looking Glass + no external monitor/dummy Windows: Line-Based vs. Message Signaled-Based Interrupts. MSI tool. ","permalink":"https://peromage.github.io/p/my-common-windows-vm-setup/","tags":["gaming","kvm","qemu","pci_passthrough","vm","windows"],"title":"My Common Windows VM Setup"},{"categories":["tech"],"contents":"Google Photo sucks.\nTroubles When exporting photos from Google Photo, a bunch of JSON files come with your photos. Those JSON files contain metadata which is supposed to be stored with your photo files. If you simple import those photo files into another photo manager you will most likely not get a chronological view. Obviously, Google does on purpose so that you will not leave it easily. However, there is a workaround that is able to merge those metadata into your photos.\nRestore the Metadate Get exiftool: https://github.com/exiftool/exiftool Export your Google Photos and extract the downloaded compressed files into a folder Save the following content to fix-args.txt # Usage: exiftool -@ fix-args.txt \u0026lt;takeout_dir\u0026gt; -r -d %s -tagsFromFile %d/%F.json -ext * --ext json -overwrite_original -progress -GPSAltitude\u0026lt;GeoDataAltitude -GPSLatitude\u0026lt;GeoDataLatitude -GPSLongitude\u0026lt;GeoDataLongitude -DateTimeOriginal\u0026lt;PhotoTakenTimeTimestamp -ModifyDate\u0026lt;PhotoLastModifiedTimeTimestamp -CreateDate\u0026lt;CreationTimeTimestamp -GPSAltitudeRef\u0026lt;GeoDataAltitude -GPSLatitudeRef\u0026lt;GeoDataLatitude -GPSLongitudeRef\u0026lt;GeoDataLongitude Execute $ exiftool -@ fix-args.txt \u0026lt;takeout_dir\u0026gt; Delete JSON files and import your photos to somewhere else This argument file contains the fields that are meaningful to me. If you need to merge additional fields you can append them to the last. For details, check the man page of exiftool.\n","permalink":"https://peromage.github.io/p/fix-metadata-in-google-photo-takeout/","tags":["google_photo"],"title":"Fix Metadata in Google Photo Takeout"},{"categories":["linux"],"contents":"This note is written for my personal convenience.\nServer Setup Installation Use system package manager to install shadowsocks-libev. In this case, for Arch Linux it is pacman.\nThere is also a Python package which can be installed by pip but it seems not to be maintained for a long time.\n$ sudo pacman -S shadowsocks-libev Shadowsocks Server Configuration Config file is located at /etc/shadowsocks/myserver.json. On FreeBSD it is /usr/local/etc/shadowsocks/myserver.json\nThe file name can vary.\n{ \u0026#34;server\u0026#34;: \u0026#34;0.0.0.0\u0026#34;, \u0026#34;server_port\u0026#34;: 8388, \u0026#34;password\u0026#34;: \u0026#34;mypassword\u0026#34;, \u0026#34;timeout\u0026#34;: 300, \u0026#34;method\u0026#34;: \u0026#34;chacha20-ietf-poly1305\u0026#34;, \u0026#34;fast_open\u0026#34;: false, \u0026#34;workers\u0026#34;: 1, \u0026#34;nameserver\u0026#34;: \u0026#34;8.8.8.8\u0026#34; } Note: For server, \u0026quot;local_address\u0026quot;: \u0026quot;127.0.0.1\u0026quot; and \u0026quot;local_port\u0026quot;: 1080 would cause problems so don\u0026rsquo;t them.\nStart the Server as A System Service The server can be started in the background but it\u0026rsquo;s not persistent after reboot.\n$ ss-server -c /etc/shadowsocks/myserver.json \u0026amp; Use systemd to make it run automatically.\nNote: The config file name has to be placed after @.\n$ sudo systemctl enable shadowsocks-libev-server@myserver $ sudo systemctl start shadowsocks-libev-server@myserver Client Helper SS Access Key Generation Script (Bash Script) This script will prompt you to input parameters that are in the config file to generate a base64 encoded link.\n#!/usr/bin/bash # Usage: this_script.sh read -p \u0026#39;Method: \u0026#39; -r ss_method read -p \u0026#39;Password: \u0026#39; -r ss_password read -p \u0026#39;Server IP: \u0026#39; -r ss_server_ip read -p \u0026#39;Server Port: \u0026#39; -r ss_server_port echo \u0026#34;ss://\u0026#34; $(printf \u0026#34;${ss_method}:${ss_password}@${ss_server_ip}:${ss_server_port}\u0026#34; | base64) SS Access Key Generation Script (JavaScript) This approch requires Node.js but it can parse config file automatically.\n// Usage: node this_script.js \u0026lt;config_file\u0026gt; let argv = process.argv.slice(2); if (argv.length \u0026lt; 1) { console.log(\u0026#34;nothing\u0026#34;); return; } const fs = require(\u0026#39;fs\u0026#39;); let config_file = argv[0]; let config_json = JSON.parse(fs.readFileSync(config_file)); let ss_url = \u0026#34;ss://\u0026#34; + btoa(`${config_json[\u0026#39;method\u0026#39;]}:${config_json[\u0026#39;password\u0026#39;]}@${config_json[\u0026#39;server\u0026#39;][0]}:${config_json[\u0026#39;server_port\u0026#39;]}`); console.log(ss_url); ","permalink":"https://peromage.github.io/p/shadowsocks-quick-setup/","tags":["shadowsocks","proxy"],"title":"Shadowsocks Quick Setup"},{"categories":["linux"],"contents":"This is a quick note of gpg-agent setup for SSH.\nQuick Setup Import your GPG authentication key. Enable SSH support for gpg-agent. $ echo enable-ssh-support \u0026gt;\u0026gt; $HOME/.gnupg/gpg-agent.conf Get the authentication keygrip. $ gpg -k --with-keygrip Add the authentication key to the keychain (replace KEYGRIP with the value obtained from the previous step) $ echo KEYGRIP \u0026gt;\u0026gt; $HOME/.gnupg/sshcontrol Add the following init code to .bashrc unset SSH_AGENT_PID export SSH_AUTH_SOCK=\u0026#34;$(gpgconf --list-dirs agent-ssh-socket)\u0026#34; export GPG_TTY=\u0026#34;$(tty)\u0026#34; gpg-connect-agent updatestartuptty /bye \u0026gt; /dev/null Kill any running ssh-agent and gpg-agent, and then open a new Bash session. Misc Export SSH Public Keys $ gpg --export-ssh-key \u0026lt;uid/fingerprint\u0026gt; ","permalink":"https://peromage.github.io/p/ssh-over-gpg-agent/","tags":["ssh","gpg"],"title":"SSH Over GPG Agent"},{"categories":["tech"],"contents":"Story Recently I\u0026rsquo;ve realized a fact that I always have needs to keep a multi-boot USB in my pocket for either Linux or Windows installation. There are a lot tools out there already but I don\u0026rsquo;t really like them. At least, I mean, they are too flashy to me. A beautiful boot menu seems not to be attractive. What I need is just a simple and practical maybe a little ugly boot device. It should be minimalist. More importantly, it has to be easy to setup with the tools on the system already and maintainable. No funky scripts.\nOld Solution - Clunky I\u0026rsquo;ve been using this solution for a very long time. Setup is pretty straight forward.\nThe partition scheme used on the USB drive is like (GPT):\nPartition Size Filesystem Note /dev/sda1 100 GB NTFS Data partition /dev/sda2 512 MB FAT EFI partition /dev/sda3 1 MB No filesystem BIOS boot partition used by GRUB /dev/sda4 8 GB NTFS Windows ISO files /dev/sda5 2 GB FAT Arch Linux ISO files So the idea is having a big data partition at the front for better access, then installing GRUB files on the second EFI partition with both EFI and BIOS support (Implemented by the third BIOS boot partition. The partition order doesn\u0026rsquo;t matter). Finally, create dedicated partitions to contain the extracted files from installation ISOs.\nWhen the USB drive is plugged in, I can use grub command line to chainload the EFI file that is located in the ISO partition, or the VBR if it\u0026rsquo;s booted with legacy mode.\nWell, it\u0026rsquo;s usable but I still feel that it is too much for a small USB drive - too many partitions. If I plug the drive in for just data exchange, there would be a a bunch of partitions mounted and the notification is quite annoying. So I started thinking that there must be a simpler way to do it.\nNew Solution - Much Better Partitioning The goal is simplicity so the new partition scheme is like this:\nPartition Size Filesystem Note /dev/sda1 100 GB NTFS Data partition /dev/sda2 512 MB FAT EFI partition /dev/sda3 1 MB No filesystem BIOS boot partition used by GRUB (Optional) The third BIOS boot partition is not really necessary since most of computers nowadays are using UEFI. If you really need the legacy compatibility, you can create one. I\u0026rsquo;ll keep it for now.\nInstalling GRUB Typical GRUB insallation but install for both EFI and BIOS.\n$ sudo mount /dev/sda2 /mnt $ sudo grub-install --target=x86_64-efi --efi-directory=/mnt --boot-directory=/mnt --removable $ sudo grub-install --target=i386-pc --boot-directory=/mnt /dev/sda Don\u0026rsquo;t forget to create a GRUB menu config file. Otherwise GRUB will boot into its command line interface (If you know what you\u0026rsquo;re doing). It\u0026rsquo;s a good idea to put a editable config file in the data partition since it will be the most used partition. However, GRUB reads the file in the EFI partition by default: (esp)/grub/grub.cfg. We can tell GRUB to read out custom config file after that.\n# (esp)/grub/grub.cfg search --set=root --file /boot.cfg configfile /boot.cfg Thus we are done with the EFI partition. All the menu configuration will go into boot.cfg in the data partition.\nLinux Installer Most of modern Linux distros support booting from a loop device. That is to say, we don\u0026rsquo;t have to extract the content of ISO files. Using GRUB loopback command can easily mount a ISO and boot from there. But chainloading the EFI or VBF is not possible. Based on the GRUB manual:\nGRUB is able to read from an image (be it one of CD or HDD) stored on any of its accessible storages (refer to see loopback command). However the OS itself should be able to find its root. This usually involves running a userspace program running before the real root is discovered.\nEFI bootloader usually will fail to find the root device by this method. However, we can manually load the kernel and ramdisk in which we can specify the root device by ourselves.\nLoad Linux ISO I\u0026rsquo;m using Arch Linux here for example.\nPut the ISO file to (data)/images/archlinux-2022.01.01-x86_64.iso. Mount ISO. We need to find the kernel loading parameters. In the file (arch)/syslinux/archiso_sys-linux.cfg we would see # Copy to RAM boot option LABEL arch64ram TEXT HELP Boot the Arch Linux install medium on BIOS with Copy-to-RAM option It allows you to install Arch Linux or perform system maintenance. ENDTEXT MENU LABEL Arch Linux install medium (x86_64, BIOS, Copy to RAM) LINUX /arch/boot/x86_64/vmlinuz-linux INITRD /arch/boot/intel-ucode.img,/arch/boot/amd-ucode.img,/arch/boot/x86_64/initramfs-linux.img APPEND archisobasedir=arch archisolabel=ARCH_202201 copytoram This is a syslinux config file. Parameters after APPEND are the ones that we\u0026rsquo;re looking for.\nThen add the following content to (data)/boot.cfg. When copying the initrd parameters, don\u0026rsquo;t forget to remove commas.\nmenuentry \u0026#34;Archiso 202201 RAM\u0026#34; { search --set=root --file /boot.cfg loopback loop /images/archlinux-2022.01.01-x86_64.iso set root=(loop) linux /arch/boot/x86_64/vmlinuz-linux archisobasedir=arch archisolabel=ARCH_202201 copytoram initrd /arch/boot/intel-ucode.img /arch/boot/amd-ucode.img /arch/boot/x86_64/initramfs-linux.img } Then the Linux installer is done. If we need more distros, the process is similar.\nWindows Installer I prefer to use NTFS as my data partition\u0026rsquo;s file system because it works on both Linux and Windows, and supports big files. Also I usually just keep one copy of Windows installer so for Windows, I can simply dump the ISO content to the data partition\u0026rsquo;s root. I don\u0026rsquo;t mind the extra a few folders there. Plus some of them can be safely deleted. Then chainloading from GRUB is possible.\nIn (data)/boot.cfg\nmenuentry \u0026#34;Windows 10 Installer\u0026#34; { search --set=root --file /boot.cfg chainloader /efi/boot/bootx64.efi } Windows PE Alternatively, I can directly boot from a small WinPE image and use dism command to extract install.wim to the target without accepting the annoying Windows partition scheme (You know what I\u0026rsquo;m talking about).\nTo create a PE image we need a Windows environment and a CMD window with admin privilege.\nCreate a virtual disk to contain PE files. Assigned with volume letter P:\\.\n\u0026gt; diskpart DISKPART\u0026gt; create vdisk file=c:\\winpe.vhd maximum=2000 type=fixed DISKPART\u0026gt; select vdisk file=c:\\winpe.vhd DISKPART\u0026gt; attach vdisk DISKPART\u0026gt; convert mbr DISKPART\u0026gt; create partition primary DISKPART\u0026gt; format fs=ntfs quick DISKPART\u0026gt; assign letter=p DISKPART\u0026gt; exit Then mount the Windows installer ISO. Assuming the assigned volume is G:\\.\n\u0026gt; dism /apply-image /imagefile:g:\\sources\\boot.wim /index:1 /applydir:p:\\ \u0026gt; dism /image:p:\\ /set-targetpath:x:\\ \u0026gt; dism /image:p:\\ /set-inputlocale:en-us \u0026gt; dism /image:p:\\ /set-userlocale:en-us Assign EFI partition with volume letter E:\\.\nBefore creating the bootloader for Windows PE, we need to backup our GRUB EFI file (Windows PE bootloader will overwrite it). Rename E:\\EFI to E:\\EFI-grub.\nCreate Windows PE bootloader.\n\u0026gt; bcdboot p:\\Windows /l en-us /s e: /f uefi Then merge both E:\\EFI and E:\\EFI-grub. If it prompts overwriting E:\\EFI\\Boot\\bootx64.efi, confirm with yes.\nThen add following content to (data)/boot.cfg.\nmenuentry \u0026#34;Windows PE\u0026#34; { search --set=root --file /boot.cfg chainloader /EFI/Microsoft/Boot/bootmgfw.efi } Loading Any ISO Some ISO is capable to be loaded directly into memory. The size of the ISO file is critical. Generally it should not exceed the physical memory. This can be done by memdisk from syslinux.\nCopy the memdisk into the EFI partition.\n$ sudo cp /usr/lib/syslinux/bios/memdisk (esp)/memdisk Then put the following content to (data)/boot.cfg. For example, loading a Windows PE ISO.\nmenuentry \u0026#34;Windows PE ISO\u0026#34; { search --set=root --file /boot.cfg linux16 memdisk iso ro initrd16 /images/winpe.iso } The End Finally I\u0026rsquo;m very satisfied with this new USB drive. Yay!\n","permalink":"https://peromage.github.io/p/minimalists-multi-boot-usb-drive/","tags":["multi_boot","usb_drive"],"title":"Minimalist's Multi-boot USB Drive"},{"categories":["emacs"],"contents":"YouTube has been pushing me a lot Emacs related contents. This is weird since mostly I watch Vim videos only. But probably this is also a great opportunity to try Emacs again.\nI have tried Emacs half year ago. I looked a lot Elisp programming fundamentals and tried a few Emacs configurations from others including Doom Emacs. However, it didn\u0026rsquo;t last long since I found that I didn\u0026rsquo;t have enough time to configure this Emacs setup as good as the Vim setup that I was using. Also using other\u0026rsquo;s configurations makes things complicated for me. They have too many packages included and I don\u0026rsquo;t know what they are.\nAfter watching a bunch of Emacs videos I decided to pick it up this time, with vanilla Emacs starting from scratch. The reason why I make my mind this time is because I found Emacs can perfectly and elegantly solve some problems that pain my ass:\nMore convenient package management. High quality packages. Easier file management in shell environment within the editor (Dired) No third party dependencies like Node.js and Python. The two major plugs that I\u0026rsquo;m using in Vim are Coc and Leaderf. They require Node.js and Python to work. Since Elisp is power enough, Emacs can handle this easily by itself. Server-client architecture. I can even replace Tmux with Emacs now. NeoVim has the similar concept but it cannot match what Emacs has. Graphical interface in X mode. This makes Emacs be able to display rich contents. Org mode. It looks great to organize todo list and take notes without switching to other applications. Evil mode. No need to worry about missing Vim\u0026rsquo;s features. Magit. Looks way better and nicer than fugitive. Elisp. Elisp is fun 😉. The migration is going slowly. Right now my main setup is still Vim + Tmux. There is a little curve learning from vanilla edition of Emacs, but It\u0026rsquo;s not a big deal compared with the first time when I started learning Vim 🙂.\nIn the end, dont\u0026rsquo;t give me wrong. Vim and Emacs both are great text editor. For me, Vim is more like a spirit, a concept. Once you\u0026rsquo;ve learned its high-efficiency key maps, you can use it everywhere. Even though I switch to Emacs I still use Vim mode together with Emacs\u0026rsquo; powerful extendability. Why not?\n","permalink":"https://peromage.github.io/p/moving-from-vim-to-emacs/","tags":["vim","emacs","text_editor"],"title":"Moving From Vim to Emacs"},{"categories":["tech"],"contents":"Background Previously I wrote a post for this dual-boot scenario. It is a little outdated. In the past year I mostly worked in the Linux environment on my old laptop, so the Windows seems not to be a necessity which occupies a dedicated partition. However, sometimes it is still needed. That is why I started thinking to improve this setup even further.\nStarting from Windows 7, Windows supports boots from a VHD file which makes it so much easier to manage. Also you are able to create differencing disks which are pretty much like snapshots.\nFor this new configuration, my plan is to use BIOS + GPT disk table + Native Linux + Native Windows booting from VHD + GRUB as the bootloader.\nPartitioning To make GPT works with BIOS. It is required to have a small partition flagged with EF02.\nThe partition scheme looks like this:\nDevice Start End Sectors Size Type /dev/sda1 34 2047 2014 1007K BIOS Boot /dev/sda2 2048 1026047 1024000 500M EFI System /dev/sda3 1026048 206546943 205520896 98G Linux Filesystem /dev/sda4 206546944 835692543 629145600 300G Linux Filesystem /dev/sda5 835692544 1465149134 629456591 300.1G Microsoft Basic Data Installing Linux Any Linux distro would work. I chose Manjaro KDE this time because I found that the Pop OS made my laptop really hot sometimes (Yeah KDE is prettier).\nThis part should be easy. The GRUB files is going into that EFI partition. For details, check GRUB wiki.\nPreparing to Install Windows I\u0026rsquo;m not going to use the standard Windwos installer since I want to install it into a VHD file. To make it work we need a Windows PE environment.\nPreparing Images Any Windows PE (Windows 7 and above) would work. The PE ISO image is going to /boot/wepe.iso.\nAlso a Windows ISO image is needed. For example a Windows 7 ISO named windows7.iso will be put in the Windows data partition.\nAdding Windows PE to GRUB Boot into Linux. Download Windows PE ISO file and move it to the EFI partition (EXT4 partitions might be problematic).\nTo load this ISO image, memdisk tool from syslinux is required. Steps as below on Arch based distro:\n# Installing syslinux $ sudo pacman -S syslinux # Copying memdisk to the boot partition $ sudo cp /usr/lib/syslinux/bios/memdisk /boot/memdisk # Adding Windows PE entry to GRUB. 1DB1-9C31 is the boot partition\u0026#39;s UUID $ sudo cat \u0026lt;\u0026lt;EOF \u0026gt;\u0026gt;/etc/grub.d/40_custom menuentry \u0026#34;WePE x64\u0026#34; { search --set=root --no-floppy --fs-uuid 1DB1-9C31 linux16 /memdisk iso ro initrd16 /wepe.iso } EOF # Updating GRUB entries $ sudo grub-mkconfig -o /boot/grub/grub.cfg Installing Windows to a VHD File After adding Windows PE to the bootloader entries, it is time to switch the working environment.\nRestart the PC, then keep pression shift key until the GRUB menu shows up. Now navigate to the Windows PE entry and get in there.\nCreating a VHD File for Windows To create a VHD file, open a command line window and enter diskpart\n# Create a VHD file assuming the NTFS data partition is assigned with D: DISKPART\u0026gt; create vdisk file=d:\\windows7.vhd maximum=64000 type=fixed DISKPART\u0026gt; select vdisk file=d:\\windows7.vhd DISKPART\u0026gt; attach vdisk # Disk table type doesn\u0026#39;t matter but using MBR for better compatibility DISKPART\u0026gt; convert mbr # Create the system partition and assign it with C: DISKPART\u0026gt; create partition primary DISKPART\u0026gt; format fs=ntfs quick DISKPART\u0026gt; assign letter=c DISKPART\u0026gt; exit Now the Windows image can be dumped into this VHD file.\nExtracting Windows Image Mount the Windows ISO image to E: volume and open a command line window\n# Get the image index. For example the desired version\u0026#39;s index is 1 \u0026gt; dism /get-wiminfo /wimfile=e:\\sources\\install.wim # Extract the image. Where E: is the Windows ISO and C: is the VHD file \u0026gt; dism /apply-image /imagefile:e:\\sources\\install.wim /index:1 /applydir:c:\\ Fixing the Windows Bootloader Stay in Windows PE. Don\u0026rsquo;t restart the PC. We still need to fix the bootloader for Windows.\nNormally Windows cannot be booted with a GPT+MBR setup. And also loading the whole Windows VHD file through memdisk is not possible because it\u0026rsquo;s too large to load into memory. To fix the boot issue a bridge is needed between Windows and GRUB.\nLuckily a small VHD image can still be loaded by memdisk.\nThe idea is: GRUB -\u0026gt; MS Bootmgr VHD -\u0026gt; Windows VHD\nCreating a Dedicated Bootloader Image for Windows It is same with the process creating a VHD file for Windows system but this time it is a smaller file (32 MB).\n# Create a small bootmgr VHD file in the data partition DISKPART\u0026gt; create vdisk file=d:\\bootmgr.vhd maximum=32 type=fixed DISKPART\u0026gt; select vdisk file=d:\\bootmgr.vhd DISKPART\u0026gt; attach vdisk DISKPART\u0026gt; convert mbr DISKPART\u0026gt; create partition primary DISKPART\u0026gt; format fs=ntfs quick DISKPART\u0026gt; assign letter=f DISKPART\u0026gt; exit Now the bootmgr VHD is mounted at F:. Then write the boot record and create boot configuration files.\n\u0026gt; bootsect /nt60 f: /mbr \u0026gt; bcdboot c:\\Windows /l en-us /s f: /f bios Fixing the BCD Entry At this point it should be working according to the Microsoft\u0026rsquo;s document. In fact it is not.\nLet\u0026rsquo;s check the BCD entries, in a command window:\n\u0026gt; bcdedit /store f:\\Boot\\BCD /enum Windows Boot Manager -------------------- identifier {bootmgr} device partition=F: description Windows Boot Manager locale en-us inherit {globalsettings} default {default} resumeobject {fcd67427-e033-11eb-8826-cdf90e3873d0} displayorder {default} toolsdisplayorder {memdiag} timeout 30 Windows Boot Loader ------------------- identifier {default} device partition=C: path \\Windows\\system32\\winload.exe description Windows 7 locale en-us inherit {bootloadersettings} osdevice partition=C: systemroot \\Windows resumeobject {fcd67427-e033-11eb-8826-cdf90e3873d0} nx OptIn detecthal Yes The device and osdevice seems to be right but once the Windows VHD is unmounted it becomes unknown. According to this BCDEdit notes, BCD entry records the partition\u0026rsquo;s information such as UUID to find the correct partition during bootup. In this case the partition can\u0026rsquo;t be found until the VHD file is mounted. But this VHD file is not mounted automatically.\nThus we need to correct this and let Bootmgr locate the VHD file properly.\nIn a command line window:\n# The identifier must match the one which is showing above \u0026gt; bcdedit /store C:\\Boot\\BCD /set {default} device vhd=[D:]\\windows7.vhd \u0026gt; bcdedit /store C:\\Boot\\BCD /set {default} osdevice vhd=[D:]\\windows7.vhd If we check the BCD entry again it doesn\u0026rsquo;t change. But if we unmount the Windows VHD it will become:\n\u0026gt; bcdedit /store f:\\Boot\\BCD /enum Windows Boot Manager -------------------- identifier {bootmgr} device partition=E: description Windows Boot Manager locale en-us inherit {globalsettings} default {default} resumeobject {fcd67427-e033-11eb-8826-cdf90e3873d0} displayorder {default} toolsdisplayorder {memdiag} timeout 30 Windows Boot Loader ------------------- identifier {default} device vhd=[C:]\\windows7.vhd path \\Windows\\system32\\winload.exe description Windows 7 locale en-us inherit {bootloadersettings} osdevice vhd=[C:]\\windows7.vhd systemroot \\Windows resumeobject {fcd67427-e033-11eb-8826-cdf90e3873d0} nx OptIn detecthal Yes The volume letter doesn\u0026rsquo;t matter, it changes dynamically. Now bootmgr is able to locate the VHD file correctly.\nAdding Windows to GRUB Restart PC and get into Linux.\nModify the GRUB config file to load bootmgr\n# Adding Windows (bootmgr) entry to GRUB. 1DB1-9C31 is the boot partition\u0026#39;s UUID $ sudo cat \u0026lt;\u0026lt;EOF \u0026gt;\u0026gt;/etc/grub.d/40_custom menuentry \u0026#34;Windows 7\u0026#34; { search --set=root --no-floppy --fs-uuid 1DB1-9C31 linux16 /memdisk harddisk initrd16 /bootmgr.vhd } EOF # Updating GRUB entries $ sudo grub-mkconfig -o /boot/grub/grub.cfg Now we can restart PC. Keep pressing shift on bootup to go to the GRUB menu. Select Windows entry to boot Windows.\nFixing Windows Initialization Error During the first time bootup, Windows might have an error showing\nWindows could not complete the installation. To install Windows on this computer, restart the installation. To solve this error:\nPress SHIFT + F10 to bring up the command prompt. Execute C:\\windows\\system32\\oobe\\msoobe. Wait for a while and the setup window will show up. Complete the setup and restart. Creating a Differencing Disk A differencing disk can be used for quick recoveries.\nTo create it, restart into the Windows PE environment. In a command line window:\n# Use the original VHD as base \u0026gt; move d:\\windows7.vhd d:\\windows7_base.vhd # Create a differencing disk based on the original one # The name of the new differencing disk has to be the name that was recorded in the BCD \u0026gt; diskpart DISKPART\u0026gt; creat vdisk file=d:\\windows7.vhd parent=d:\\windows7_base.vhd Then all changes made in the future will go into the differencing disk. If system goes wrong one day, simply deleting the the differencing disk and creating a new one would quickly recover from the crysis.\nNOTE: After creating the differencing disk, the base VHD is not supposed to be modified.\nReferences GRUB wiki BIOS + GPT + GRUB + Linux + Windows 折腾笔记 在 VHD 中安装 Windows 7 Hack Bootmgr to boot Windows in BIOS to GPT Boot to a virtual hard disk: Add a VHDX or VHD to the boot menu BCDEdit notes 100% Solved:Windows could not complete the installation ","permalink":"https://peromage.github.io/p/dual-booting-windows-vhd-and-native-linux-on-a-bios-gpt-pc/","tags":["dual_boot","grub","linux","windows"],"title":"Dual-booting Windows VHD and Native Linux on a BIOS+GPT PC"},{"categories":["tech"],"contents":"因为最近弄自己的博客，涉及到了版本库嵌套的问题。记下来也算是给自己一个备忘。\n为什么有这样的需求 版本库嵌套很好理解，就是在一个 Git 仓库里面包含了其他的 Git 仓库。通常有这样的需求往往涉及到协同开发。比如这里有一个插件单独的 Git 仓库姑且叫“Plugin”。现在我创建了一个自己的项目，其中需要用到这个“Plugin”插件。通常比较笨的办法就是把插件库源码拖下来，复制到自己的项目里。但是这样当插件库更新的时候，插件源码更新往往比较麻烦。而且如果在使用的过程中修改了插件的源码，也不便于插件单独的版本控制，更别说为插件库贡献代码了。但如果插件单独以 Git 仓库存在于我的项目目录中，以上的问题就解决了。\n在 Git 里面提供了两种方式实现上述需求，那就是 Subtree 和 Submodule。\nSubmodule Submodule 是 Git 里面最早提供的一种方法。顾名思义“子模块”。\n添加子模块 执行\n$ git submodule add \u0026lt;repo\u0026gt; \u0026lt;module_path\u0026gt; 此时运行 git status 可以看到子模块对应的文件夹和一个叫做 .gitmodules 文件被添加进了暂存区。其中 .gitmodules 是用于记录子模块相关信息的。之后主项目里面的操作照常提交就可以了。\n修改子模块 但如果在开发的途中修改了子模块的代码，需要单独到子模块对应的根目录里面进行子模块单独的提交操作。在主项目里面虽然可以看到子模块有变更，但是无法看到具体的更改操作，而是将其看作一个模块整体。一旦子模块产生了新的提交，主项目里面可以看到子模块的 HEAD 变化，从而主项目也应当产生一个新的提交以记录对应关系。 换句话说，主项目就是靠着记录子模块 HEAD 值来判断依赖的。子模块的代码最后将不会进入主项目的版本库里面（只有 HEAD 值）。\n现在子模块有了新的提交，为了将服务器上的代码更新，我们只需要进入子模块对应的更目录执行 push 操作就可以了。\n更新子模块 此时子模块上游有了新的代码，我们需要将其整合到当前的项目中。有两种方法。\n在主项目根目录下运行\n$ git submodule foreach git pull 或者切换到子模块的根目录下面\n$ git pull 克隆项目 克隆主项目的时候子模块并不会拉取到本地，如果进入对应的目录会发现是空的。 此时应当\n$ git submodule init 保持最新\n$ git submodule update 或者可以直接一条命令搞定\n$ git clone --recursive \u0026lt;repo\u0026gt; 删除子模块 Git 中没有提供直接删除的命令，需要手动完成删除操作。\n反向初始化子模块\n$ git submodule deinit --force \u0026lt;module_path\u0026gt; 或者直接删掉 .git/config 里相关信息\n移除子模块\n$ git rm \u0026lt;module_path\u0026gt; 如果暂存区还有\n$ git rm --cached \u0026lt;module_path\u0026gt; 子模块的坑 提交的坑 假设有 A B 两个人同时在开发一个项目，这个项目里面也包含了一个子模块。此时 A 修改了业务代码，同时修改了一个子模块里面的一个 bug 。A 将这次修改提交，主项目的提交里面指向了子模块新的 HEAD1 ，然后把主项目的版本库 push 到了服务器，但是没有 push 子模块。B 此时 pull 了主项目，然后 update 子模块，被告知找不到子模块的 HEAD1 。因为指向 HEAD1 的提交还在 A 本地机器上。 这就是子模块提交的坑。在多个模块存在的时候操作非常繁琐。\n初始化的坑 在执行 git submodule init ， git submodule update 之后，此时修改子模块可能出现 HEAD 处于游离状态的的提示。如果不注意极有可能出现丢失提交的可能。 解决办法，在以上两条命令之后执行一次检出\n$ git checkout \u0026lt;branch\u0026gt; Subtree 添加子项目 首先添加子项目对应的远程服务器\n$ git remote add \u0026lt;subrepo_name\u0026gt; \u0026lt;subrepo_remote\u0026gt; 拉取一下\n$ git fetch \u0026lt;subrepo_name\u0026gt; 添加子项目到父项目里面\n$ git subtree add --squash --prefix=\u0026lt;subrepo_path\u0026gt; \u0026lt;subrepo_name\u0026gt; \u0026lt;branch\u0026gt; 参数 --squash 作用在于合并子项目所有提交为一个，并 merge 到父项目的历史中，这样只会出现两个提交记录，避免子项目的提交历史污染父项目。更多讨论可以看这里。\n修改子项目 添加完毕之后照常修改提交各种操作，父项目能够跟踪子项目里面的所有变更。子项目被当做一个正常的子文件夹处理。\n如果现在修改了子项目里的一个 bug 并且想要反馈给上游，可以这样操作\n$ git subtree push --prefix=\u0026lt;subrepo_path\u0026gt; \u0026lt;subrepo_name\u0026gt; \u0026lt;bug_fixed\u0026gt; 这个操作可以将父项目里所有涉及子项目修改的提交检出。这样在远程仓库里面会出现一个叫做 bug_fixed 的分支。\n或者也可以这样操作\n$ git subtree split --prefix=\u0026lt;subrepo_path\u0026gt; --branch \u0026lt;new_branch_name\u0026gt; 这个操作跟上面一样将父项目里所有涉及子项目修改的提交检出，并且把子项目的根文件夹设为整个项目的根文件夹，然后检出为父项目的一个新的分支。\n然后推送给上游\n$ git push \u0026lt;subrepo_remote\u0026gt; \u0026lt;new_branch_name\u0026gt;:\u0026lt;bug_fixed\u0026gt; 之后删除对应本地分支就可以了。\n更新子项目 拉取非常方便\n$ git subtree pull --prefix=\u0026lt;subrepo_path\u0026gt; \u0026lt;subrepo_name\u0026gt; \u0026lt;branch\u0026gt; 删除子项目 因为子项目在父项目里面就是被当做一个普通的文件夹处理的，所以直接移除文件夹并提交就可以了。\nSubmodule vs. Subtree Git 官方推荐使用新的 Subtree ，事实证明的确比 Submodule 方便不少。Subtree 不会产生额外的文件，而且子项目的代码包含在父项目里面，不会出现前面提到的坑的问题。具体应用上的对比可以参考这篇文章。Subtree 对于代码迭代较快的项目尤为适合。\n但也不是说 Submodule 一无是处， Submodule 在我感觉最大的意义在于可以隔离子项目的业务代码，并且记录严格的依赖关系。对于一些子模块更新较慢的项目还是比较适合的。\n参考 subtree_usage subtree_squash ","permalink":"https://peromage.github.io/p/git%E4%B8%AD%E7%9A%84subtree%E5%92%8Csubmodule/","tags":["git"],"title":"Git中的Subtree和Submodule"},{"categories":["tech"],"contents":"0x00 情况简述 由于开发需要 Linux 环境，所以将老的那台笔记本改造成了双系统。 这台电脑的基本情况是这样的，64GB 固态硬盘 + 720GB 机械硬盘（实际可用空间有折损，这里为了表示方便），Windows 10 已经安装到了固态硬盘上。由于主板较老，只能支持 BIOS。巨硬又说过 Windows 只能支持 BIOS + MBR，所以第一块主位（Master）上的固态硬盘就只能采用 MBR 分区表，分成了两个区，500MB 用作启动分区，剩下的部分全部划给了系统分区。 但是 Linux 表示没有巨硬这种尿性，所以为什么不使用更先进的 GPT 分区表？因此从位（Slave）上的机械硬盘被我分成了这个样子：\n大小 挂载点 文件系统 备注 10 MB None No File System BIOS 启动分区 500 MB /boot EXT4 引导 100 GB / EXT4 系统 199.5GB /home EXT4 用户 420 GB None NTFS Windows 数据 BIOS 启动分区 1MB 足以，我只是考虑到后续扩展问题。之后在第二块硬盘上安装了 Arch Linux。\n0x01 有啥好折腾的？ 双系统安装好以后相安无事，BIOS 默认从主位固态硬盘启动。也就是说开机不进行任何操作的话，默认进入的是 Windows 10。只有在开机的时候使用 BIOS 的 Fast Boot 功能，选择从第二块硬盘启动才能进入 Arch Linux。换句话说两个系统彼此都是透明的。 但是作为一个强迫症和完美主义者，万一我想进入 Linux，但是开机的时候错过了，岂不是要重启一次才行？或者万一我又反悔想进入 Windows 又要重启一次？这怎么能忍，所以才有了这次的折腾……\n0x02 在 GRUB 中添加引导菜单 对于 GRUB （注：这里所说的 GRUB 指的是 GRUB 2 而不是 GRUB Legacy） 引导的 Linux 来说，切换到 Windows 的 bootmgr 是一件很容易的事情，最新版的 GRUB 可以直接启动 bootmgr 而不需要之前的 chainloading 模式。 进入 Arch Linux，以 root 权限编辑 /etc/grub.d/40_custom ，加入以下菜单：\nmenuentry \u0026#34;Switch to Microsoft Boot Manager\u0026#34; { insmod part_msdos insmod ntfs insmod search_fs_uuid insmod ntldr search --fs-uuid --set=root 69B235F6749E84CE ntldr /bootmgr } insmod 是用于加载必要的模块以便 GRUB 识别并正确启动 Windows。值得注意的是， search 一行指定的 UUID 与 Linux 下 lsblk -f 看到的 UUID 是不一样的，需要使用\n$ sudo grub-probe --target=fs_uuid -d /dev/sda1 来获取 GRUB 下对应的分区 UUID。这个例子中，Windows 启动分区是 sda1 。UUID 是唯一的，勿照搬。\n当然也可以使用传统的 chainloading 模式：\nmenuentry \u0026#34;Switch to Microsoft Boot Manager\u0026#34; { insmod part_msdos insmod ntfs insmod search_fs_uuid search --fs-uuid --set=root 69B235F6749E84CE chainloader +1 } 保存以后，执行\n$ sudo grub-mkconfig -o /boot/grub/grub.cfg 以便更新启动菜单。\n不推荐直接编辑 /boot/grub/grub.cfg ，因为上述命令会覆盖这个文件，不便于自定义菜单的管理。 这样就可以直接跳转到 bootmgr ，让它去启动 Windows。\n0x03 BCD 寻思 BCD 是Windows Vista 之后使用的一种启动管理器。有个非常蛋疼的问题就在于，BCD 并不支持 EXT4 分区格式，所以没有办法读到 GRUB。查阅了相关资料，给出的解决办法就是，将 /boot 分区格式化成 FAT32 的文件系统。难道我还得再折腾一次文件系统？直觉告诉我一定还有其他的办法。 既然 BCD 没办法直接读 EXT4 分区里面的东西，我们可以曲线救国。BCD 里面提供了一种实模式启动的方式，允许读取一个包含了启动代码的文件。所以一种解决办法就是 BCD → MBR → VBR → Bootloader 。由于 GPT 磁盘的第一个扇区被划分成了 Protective MBR，用于兼容 BIOS，所以在 Linux 使用：\n$ sudo dd if=/dev/sdb of=/mnt/reserved/grub.bin bs=512 count=1 可以将第二块硬盘的第一扇区里面的启动代码导出到一个文件，然后使用 BCD 加载这个文件就可以启动 GRUB了。 果真如此？ 事实是，这种方法可行，但是并不适用我的情况，因为这是建立在 Windows 和 Linux 安装在同一块硬盘上的情形。 grub.bin 并不能够跨分区寻找 VBR。难道只能作罢？肯定不可能，不然就没有这篇文章了。 查阅了若干文档之后，得知 GRUB 提供了一个 叫做 lnxboot.img 文件，可以将 GRUB 启动阶段模拟成一个可以启动的 Linux 内核，然后挂载 core.img 里面必要的模块，从而顺利启动 GRUB。那么将之前的思路修改成 BCD → VBR → Bootloader 就行了，即既然 MBR 不能跨分区以及识别 GPT，那么我们就换成一个可以胜任的不就行了。\n0x04 制作启动镜像 进入 Arch Linux。虽然在 /boot/grub/i386-pc/ 目录下有一个用于启动的 core.img 文件，这个文件里面指定的模块路径是相对路径，使用它启动依然会显示错误，需要指定绝对路径以保证万无一失。那么我们就来手动生成一个，顺便集成一些我们需要的模块。 注意，启动镜像稍后会被放在 Windows 的启动分区下面（BCD 的启动分区），所以还需要知道模块所在分区的位置。在 GRUB 中表示磁盘的方式有所不同，如 (hd0,msdos1) 表示第一块磁盘，使用 MBR 分区表，第一个分区。 (hd1,gpt2) 表示第二块磁盘，使用 GPT分区表，第二个分区。括号不可省，磁盘和分区的起始数字不一样。\n使用 grub-probe 来获取 /boot 分区信息。这个例子得到的是 hd1,gpt2 ：\n$ sudo grub-probe --target=bios_hints /boot 生成 core.img ：\n$ sudo grub-mkimage --output=/tmp/core.img --prefix=\\(hd1,gpt2\\)/grub --format=i386-pc biosdisk part_msdos part_gpt ext2 注意像我这样 /boot 单独分区，prefix 就不需要写成 \\\\(hd1,gpt2\\\\)/boot/grub ，毕竟已经在 /boot 里面了嘛。默认没有 GPT 支持，所以还需要添加 GPT 模块。\n生成启动镜像： 按照 GRUB 的帮助文档， lnxboot.img 需要放在 core.img 之前，由 lnxboot.img 来加载 core.img 。所幸 BCD 可以一次读取大于一个扇区（512B）的内容，所以将这两个文件合并一下即可：\n$ sudo cat /usr/lib/grub/i386-pc/lnxboot.img /tmp/core.img \u0026gt; /tmp/grub4bcd.img 然后将 grub4bcd.img 放到 Windows 启动分区根目录下面就可以了。注意内核默认只能以只读模式挂载 NFTS 文件系统，需要安装扩展包才能读写：\n$ sudo pacman -S ntfs-3g 然后挂载（安装了上述扩展包之后甚至不用指定参数）：\n$ sudo mount /dev/sda1 /mnt/reserved 现在就可以顺利地将启动镜像复制到 Windows 启动分区下面了。\n0x05 在 BCD 中添加引导菜单 重启进入 Windows 10。以管理员权限打开命令行。\n添加入口：\n\u0026gt; bcdedit /create /d \u0026#34;Switch to GRUB\u0026#34; /application bootsector 会返回一串 UUID，复制下来。之后 UUID 的地方我用 {ID} 表示，用刚才得到的替换即可。\n设置启动分区：\n\u0026gt; bcdedit /set {ID} device boot 设置启动文件：\n\u0026gt; bcdedit /set {ID} path /grub4bcd.img 将入口添加进启动菜单：\n\u0026gt; bcdedit /displayorder {ID} /addlast 关闭 Metro 启动菜单（不关闭的话切换时会重启，建议关闭）：\n\u0026gt; bcdedit /set {default} bootmenupolicy legacy 最后关闭 Windows 10 的 Hybrid 开机功能，否则可能会导致 Windows 丢失数据：\n\u0026gt; powercfg /h off 0x06 后记 现在终于可以愉快地切换两个引导菜单了。其实使用 GRUB 来管理两个系统是较为简单的办法。 更为简单的办法是，先装 Windows 然后装 Ubuntu，后者会自动搞定这些麻烦事。╮(╯_╰)╭\n0x07 参考资料 https://www.gnu.org/software/grub/manual/grub.html#Images http://askubuntu.com/questions/180033/how-to-add-different-drive-ubuntu-to-bcd-manually https://wiki.archlinux.org/index.php/Talk:Dual_boot_with_Windows https://wiki.archlinux.org/index.php/Dual_boot_with_Windows ","permalink":"https://peromage.github.io/p/windows-linux%E5%8F%8C%E7%B3%BB%E7%BB%9F%E5%BC%95%E5%AF%BC%E6%89%8B%E8%AE%B0/","tags":["dual_boot","windows","grub","linux"],"title":"Windows+Linux双系统引导手记"}]